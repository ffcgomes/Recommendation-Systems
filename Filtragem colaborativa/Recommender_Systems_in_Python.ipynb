{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender Systems in Python.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTJvG5jDr7gX"
      },
      "source": [
        "#Recommender Systems in Python\r\n",
        "\r\n",
        "This notebook is a practical introduction to the main Recommender System (RecSys) techniques. The objective of a RecSys is to recommend relevant items for users, based on their preference. Preference and relevance are subjective, and they are generally inferred by items users have consumed previously.\r\n",
        "The main families of methods for RecSys are:\r\n",
        "\r\n",
        "Collaborative Filtering: This method makes automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on a set of items, A is more likely to have B's opinion for a given item than that of a randomly chosen person.\r\n",
        "Content-Based Filtering: This method uses only information about the description and attributes of the items users has previously consumed to model user's preferences. In other words, these algorithms try to recommend items that are similar to those that a user liked in the past (or is examining in the present). In particular, various candidate items are compared with items previously rated by the user and the best-matching items are recommended.\r\n",
        "Hybrid methods: Recent research has demonstrated that a hybrid approach, combining collaborative filtering and content-based filtering could be more effective than pure approaches in some cases. These methods can also be used to overcome some of the common problems in recommender systems such as cold start and the sparsity problem.\r\n",
        "In this notebook, we use a dataset we've shared on Kaggle Datasets: Articles Sharing and Reading from CI&T Deskdrop.\r\n",
        "We will demonstrate how to implement Collaborative Filtering, Content-Based Filtering and Hybrid methods in Python, for the task of providing personalized recommendations to the users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwOvlzTQr4TJ"
      },
      "source": [
        "import numpy as np\r\n",
        "import scipy\r\n",
        "import pandas as pd\r\n",
        "import math\r\n",
        "import random\r\n",
        "import sklearn\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from scipy.sparse import csr_matrix\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "from scipy.sparse.linalg import svds\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxFt5XLisL-4"
      },
      "source": [
        "#Loading data: CI&T Deskdrop dataset\r\n",
        "In this section, we load the Deskdrop dataset, which contains a real sample of 12 months logs (Mar. 2016 - Feb. 2017) from CI&T's Internal Communication platform (DeskDrop). It contains about 73k logged users interactions on more than 3k public articles shared in the platform. It is composed of two CSV files:\r\n",
        "\r\n",
        "shared_articles.csv\r\n",
        "users_interactions.csv\r\n",
        "Take a look in this kernels for a better picture of the dataset:\r\n",
        "\r\n",
        "Deskdrop datasets EDA\r\n",
        "DeskDrop Articles Topic Modeling\r\n",
        "shared_articles.csv\r\n",
        "Contains information about the articles shared in the platform. Each article has its sharing date (timestamp), the original url, title, content in plain text, the article' lang (Portuguese: pt or English: en) and information about the user who shared the article (author).\r\n",
        "\r\n",
        "There are two possible event types at a given timestamp:\r\n",
        "\r\n",
        "CONTENT SHARED: The article was shared in the platform and is available for users.\r\n",
        "CONTENT REMOVED: The article was removed from the platform and not available for further recommendation.\r\n",
        "For the sake of simplicity, we only consider here the \"CONTENT SHARED\" event type, assuming (naively) that all articles were available during the whole one year period. For a more precise evaluation (and higher accuracy), only articles that were available at a given time should be recommended, but we let this exercice for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "nwfhGxDLsiC9",
        "outputId": "b920f576-d039-4830-f181-d9775f2a1064"
      },
      "source": [
        "articles_df = pd.read_csv('/content/shared_articles.csv')\r\n",
        "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\r\n",
        "articles_df.head(5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>authorPersonId</th>\n",
              "      <th>authorSessionId</th>\n",
              "      <th>authorUserAgent</th>\n",
              "      <th>authorRegion</th>\n",
              "      <th>authorCountry</th>\n",
              "      <th>contentType</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1459193988</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-4110354420726924665</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.nytimes.com/2016/03/28/business/dea...</td>\n",
              "      <td>Ethereum, a Virtual Currency, Enables Transact...</td>\n",
              "      <td>All of this work is still very early. The firs...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1459194146</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-7292285110016212249</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://cointelegraph.com/news/bitcoin-future-w...</td>\n",
              "      <td>Bitcoin Future: When GBPcoin of Branson Wins O...</td>\n",
              "      <td>The alarm clock wakes me at 8:00 with stream o...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1459194474</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-6151852268067518688</td>\n",
              "      <td>3891637997717104548</td>\n",
              "      <td>-1457532940883382585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>https://cloudplatform.googleblog.com/2016/03/G...</td>\n",
              "      <td>Google Data Center 360Â° Tour</td>\n",
              "      <td>We're excited to share the Google Data Center ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1459194497</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>2448026894306402386</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>https://bitcoinmagazine.com/articles/ibm-wants...</td>\n",
              "      <td>IBM Wants to \"Evolve the Internet\" With Blockc...</td>\n",
              "      <td>The Aite Group projects the blockchain market ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1459194522</td>\n",
              "      <td>CONTENT SHARED</td>\n",
              "      <td>-2826566343807132236</td>\n",
              "      <td>4340306774493623681</td>\n",
              "      <td>8940341205206233829</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HTML</td>\n",
              "      <td>http://www.coindesk.com/ieee-blockchain-oxford...</td>\n",
              "      <td>IEEE to Talk Blockchain at Cloud Computing Oxf...</td>\n",
              "      <td>One of the largest and oldest organizations fo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp  ... lang\n",
              "1  1459193988  ...   en\n",
              "2  1459194146  ...   en\n",
              "3  1459194474  ...   en\n",
              "4  1459194497  ...   en\n",
              "5  1459194522  ...   en\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4wH2OWVtUaA"
      },
      "source": [
        "#users_interactions.csv\r\n",
        "Contains logs of user interactions on shared articles. It can be joined to articles_shared.csv by contentId column.\r\n",
        "\r\n",
        "The eventType values are:\r\n",
        "\r\n",
        "VIEW: The user has opened the article.\r\n",
        "LIKE: The user has liked the article.\r\n",
        "COMMENT CREATED: The user created a comment in the article.\r\n",
        "FOLLOW: The user chose to be notified on any new comment in the article.\r\n",
        "BOOKMARK: The user has bookmarked the article for easy return in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Nu4_69yEtYIz",
        "outputId": "400d419c-fd79-4344-d1c1-e43da02d719a"
      },
      "source": [
        "interactions_df = pd.read_csv('/content/users_interactions.csv')\r\n",
        "interactions_df.head(10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>eventType</th>\n",
              "      <th>contentId</th>\n",
              "      <th>personId</th>\n",
              "      <th>sessionId</th>\n",
              "      <th>userAgent</th>\n",
              "      <th>userRegion</th>\n",
              "      <th>userCountry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1465413032</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-3499919498720038879</td>\n",
              "      <td>-8845298781299428018</td>\n",
              "      <td>1264196770339959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1465412560</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>8890720798209849691</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "      <td>3621737643587579081</td>\n",
              "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...</td>\n",
              "      <td>NY</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1465416190</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>-1130272294246983140</td>\n",
              "      <td>2631864456530402479</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1465413895</td>\n",
              "      <td>FOLLOW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>344280948527967603</td>\n",
              "      <td>-3167637573980064150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465412290</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-7820640624231356730</td>\n",
              "      <td>-445337111692715325</td>\n",
              "      <td>5611481178424124714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1465413742</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>-8763398617720485024</td>\n",
              "      <td>1395789369402380392</td>\n",
              "      <td>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...</td>\n",
              "      <td>MG</td>\n",
              "      <td>BR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1465415950</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-8864073373672512525</td>\n",
              "      <td>3609194402293569455</td>\n",
              "      <td>1143207167886864524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1465415066</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>-1492913151930215984</td>\n",
              "      <td>4254153380739593270</td>\n",
              "      <td>8743229464706506141</td>\n",
              "      <td>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...</td>\n",
              "      <td>SP</td>\n",
              "      <td>BR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1465413762</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>310515487419366995</td>\n",
              "      <td>344280948527967603</td>\n",
              "      <td>-3167637573980064150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1465413771</td>\n",
              "      <td>VIEW</td>\n",
              "      <td>3064370296170038610</td>\n",
              "      <td>3609194402293569455</td>\n",
              "      <td>1143207167886864524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp eventType  ...  userRegion  userCountry\n",
              "0  1465413032      VIEW  ...         NaN          NaN\n",
              "1  1465412560      VIEW  ...          NY           US\n",
              "2  1465416190      VIEW  ...         NaN          NaN\n",
              "3  1465413895    FOLLOW  ...         NaN          NaN\n",
              "4  1465412290      VIEW  ...         NaN          NaN\n",
              "5  1465413742      VIEW  ...          MG           BR\n",
              "6  1465415950      VIEW  ...         NaN          NaN\n",
              "7  1465415066      VIEW  ...          SP           BR\n",
              "8  1465413762      VIEW  ...         NaN          NaN\n",
              "9  1465413771      VIEW  ...         NaN          NaN\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpfjhfVOtxv4"
      },
      "source": [
        "#Data munging\r\n",
        "As there are different interactions types, we associate them with a weight or strength, assuming that, for example, a comment in an article indicates a higher interest of the user on the item than a like, or than a simple view."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE_EBR7vt0RP"
      },
      "source": [
        "event_type_strength = {\r\n",
        "   'VIEW': 1.0,\r\n",
        "   'LIKE': 2.0, \r\n",
        "   'BOOKMARK': 2.5, \r\n",
        "   'FOLLOW': 3.0,\r\n",
        "   'COMMENT CREATED': 4.0,  \r\n",
        "}\r\n",
        "\r\n",
        "interactions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength[x])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvB2WnuWeNRx"
      },
      "source": [
        "Recommender systems have a problem known as user cold-start, in which is hard do provide personalized recommendations for users with none or a very few number of consumed items, due to the lack of information to model their preferences.\r\n",
        "For this reason, we are keeping in the dataset only users with at leas 5 interactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsLexhNVeQjY",
        "outputId": "28a726ff-2600-422e-a8ba-6ddfb1df29f7"
      },
      "source": [
        "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\r\n",
        "print('# users: %d' % len(users_interactions_count_df))\r\n",
        "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\r\n",
        "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# users: 1895\n",
            "# users with at least 5 interactions: 1140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-M0oWm6em9a",
        "outputId": "f8806bef-afe8-4625-80fc-f7f7b12fb728"
      },
      "source": [
        "print('# of interactions: %d' % len(interactions_df))\r\n",
        "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \r\n",
        "               how = 'right',\r\n",
        "               left_on = 'personId',\r\n",
        "               right_on = 'personId')\r\n",
        "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of interactions: 72312\n",
            "# of interactions from users with at least 5 interactions: 69868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAmMOwfreysU"
      },
      "source": [
        "In Deskdrop, users are allowed to view an article many times, and interact with them in different ways (eg. like or comment). Thus, to model the user interest on a given article, we aggregate all the interactions the user has performed in an item by a weighted sum of interaction type strength and apply a log transformation to smooth the distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "I0RSLs0Lezpv",
        "outputId": "2346f09f-075e-45b9-c04b-e37e05b8b6d3"
      },
      "source": [
        "def smooth_user_preference(x):\r\n",
        "    return math.log(1+x, 2)\r\n",
        "    \r\n",
        "interactions_full_df = interactions_from_selected_users_df \\\r\n",
        "                    .groupby(['personId', 'contentId'])['eventStrength'].sum() \\\r\n",
        "                    .apply(smooth_user_preference).reset_index()\r\n",
        "print('# of unique user/item interactions: %d' % len(interactions_full_df))\r\n",
        "interactions_full_df.head(10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of unique user/item interactions: 39106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8949113594875411859</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8377626164558006982</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8208801367848627943</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-8187220755213888616</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-7423191370472335463</td>\n",
              "      <td>3.169925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-7331393944609614247</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6872546942144599345</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6728844082024523434</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6590819806697898649</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-9223121837663643404</td>\n",
              "      <td>-6558712014192834002</td>\n",
              "      <td>1.584963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              personId            contentId  eventStrength\n",
              "0 -9223121837663643404 -8949113594875411859       1.000000\n",
              "1 -9223121837663643404 -8377626164558006982       1.000000\n",
              "2 -9223121837663643404 -8208801367848627943       1.000000\n",
              "3 -9223121837663643404 -8187220755213888616       1.000000\n",
              "4 -9223121837663643404 -7423191370472335463       3.169925\n",
              "5 -9223121837663643404 -7331393944609614247       1.000000\n",
              "6 -9223121837663643404 -6872546942144599345       1.000000\n",
              "7 -9223121837663643404 -6728844082024523434       1.000000\n",
              "8 -9223121837663643404 -6590819806697898649       1.000000\n",
              "9 -9223121837663643404 -6558712014192834002       1.584963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVtKG-ZPfOwY"
      },
      "source": [
        "#Evaluation\r\n",
        "Evaluation is important for machine learning projects, because it allows to compare objectivelly different algorithms and hyperparameter choices for models.\r\n",
        "One key aspect of evaluation is to ensure that the trained model generalizes for data it was not trained on, using Cross-validation techniques. We are using here a simple cross-validation approach named holdout, in which a random data sample (20% in this case) are kept aside in the training process, and exclusively used for evaluation. All evaluation metrics reported here are computed using the test set.\r\n",
        "\r\n",
        "Ps. A more robust evaluation approach could be to split train and test sets by a reference date, where the train set is composed by all interactions before that date, and the test set are interactions after that date. For the sake of simplicity, we chose the first random approach for this notebook, but you may want to try the second approach to better simulate how the recsys would perform in production predicting \"future\" users interactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOXqJ9YWfRr-",
        "outputId": "c7af3e5e-de6f-4e19-a17b-d5fd70bc3248"
      },
      "source": [
        "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\r\n",
        "                                   stratify=interactions_full_df['personId'], \r\n",
        "                                   test_size=0.20,\r\n",
        "                                   random_state=42)\r\n",
        "\r\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\r\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# interactions on Train set: 31284\n",
            "# interactions on Test set: 7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os-jdZXif8Ec"
      },
      "source": [
        "In Recommender Systems, there are a set metrics commonly used for evaluation. We chose to work with Top-N accuracy metrics, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted in test set.\r\n",
        "This evaluation method works as follows:\r\n",
        "\r\n",
        "For each user\r\n",
        "For each item the user has interacted in test set\r\n",
        "Sample 100 other items the user has never interacted.\r\n",
        "Ps. Here we naively assume those non interacted items are not relevant to the user, which might not be true, as the user may simply not be aware of those not interacted items. But let's keep this assumption.\r\n",
        "Ask the recommender model to produce a ranked list of recommended items, from a set composed one interacted item and the 100 non-interacted (\"non-relevant!) items\r\n",
        "Compute the Top-N accuracy metrics for this user and interacted item from the recommendations ranked list\r\n",
        "Aggregate the global Top-N accuracy metrics\r\n",
        "The Top-N accuracy metric choosen was Recall@N which evaluates whether the interacted item is among the top N items (hit) in the ranked list of 101 recommendations for a user.\r\n",
        "Ps. Other popular ranking metrics are NDCG@N and MAP@N, whose score calculation takes into account the position of the relevant item in the ranked list (max. value if relevant item is in the first position). You can find a reference to implement this metrics in this post."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x09BhqCXf9Mp"
      },
      "source": [
        "#Indexing by personId to speed up the searches during evaluation\r\n",
        "interactions_full_indexed_df = interactions_full_df.set_index('personId')\r\n",
        "interactions_train_indexed_df = interactions_train_df.set_index('personId')\r\n",
        "interactions_test_indexed_df = interactions_test_df.set_index('personId')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr4aul0XgwFz"
      },
      "source": [
        "def get_items_interacted(person_id, interactions_df):\r\n",
        "    # Get the user's data and merge in the movie information.\r\n",
        "    interacted_items = interactions_df.loc[person_id]['contentId']\r\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAp2lLXvgzsY"
      },
      "source": [
        "#Top-N accuracy metrics consts\r\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\r\n",
        "\r\n",
        "class ModelEvaluator:\r\n",
        "\r\n",
        "\r\n",
        "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\r\n",
        "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\r\n",
        "        all_items = set(articles_df['contentId'])\r\n",
        "        non_interacted_items = all_items - interacted_items\r\n",
        "\r\n",
        "        random.seed(seed)\r\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\r\n",
        "        return set(non_interacted_items_sample)\r\n",
        "\r\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \r\n",
        "            try:\r\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\r\n",
        "            except:\r\n",
        "                index = -1\r\n",
        "            hit = int(index in range(0, topn))\r\n",
        "            return hit, index\r\n",
        "\r\n",
        "    def evaluate_model_for_user(self, model, person_id):\r\n",
        "        #Getting the items in test set\r\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\r\n",
        "        if type(interacted_values_testset['contentId']) == pd.Series:\r\n",
        "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\r\n",
        "        else:\r\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \r\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset) \r\n",
        "\r\n",
        "        #Getting a ranked recommendation list from a model for a given user\r\n",
        "        person_recs_df = model.recommend_items(person_id, \r\n",
        "                                               items_to_ignore=get_items_interacted(person_id, \r\n",
        "                                                                                    interactions_train_indexed_df), \r\n",
        "                                               topn=10000000000)\r\n",
        "\r\n",
        "        hits_at_5_count = 0\r\n",
        "        hits_at_10_count = 0\r\n",
        "        #For each item the user has interacted in test set\r\n",
        "        for item_id in person_interacted_items_testset:\r\n",
        "            #Getting a random sample (100) items the user has not interacted \r\n",
        "            #(to represent items that are assumed to be no relevant to the user)\r\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \r\n",
        "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \r\n",
        "                                                                          seed=item_id%(2**32))\r\n",
        "\r\n",
        "            #Combining the current interacted item with the 100 random items\r\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\r\n",
        "\r\n",
        "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\r\n",
        "            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \r\n",
        "            valid_recs = valid_recs_df['contentId'].values\r\n",
        "            #Verifying if the current interacted item is among the Top-N recommended items\r\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\r\n",
        "            hits_at_5_count += hit_at_5\r\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\r\n",
        "            hits_at_10_count += hit_at_10\r\n",
        "\r\n",
        "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \r\n",
        "        #when mixed with a set of non-relevant items\r\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\r\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\r\n",
        "\r\n",
        "        person_metrics = {'hits@5_count':hits_at_5_count, \r\n",
        "                          'hits@10_count':hits_at_10_count, \r\n",
        "                          'interacted_count': interacted_items_count_testset,\r\n",
        "                          'recall@5': recall_at_5,\r\n",
        "                          'recall@10': recall_at_10}\r\n",
        "        return person_metrics\r\n",
        "\r\n",
        "    def evaluate_model(self, model):\r\n",
        "        #print('Running evaluation for users')\r\n",
        "        people_metrics = []\r\n",
        "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\r\n",
        "            #if idx % 100 == 0 and idx > 0:\r\n",
        "            #    print('%d users processed' % idx)\r\n",
        "            person_metrics = self.evaluate_model_for_user(model, person_id)  \r\n",
        "            person_metrics['_person_id'] = person_id\r\n",
        "            people_metrics.append(person_metrics)\r\n",
        "        print('%d users processed' % idx)\r\n",
        "\r\n",
        "        detailed_results_df = pd.DataFrame(people_metrics) \\\r\n",
        "                            .sort_values('interacted_count', ascending=False)\r\n",
        "        \r\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\r\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\r\n",
        "        \r\n",
        "        global_metrics = {'modelName': model.get_model_name(),\r\n",
        "                          'recall@5': global_recall_at_5,\r\n",
        "                          'recall@10': global_recall_at_10}    \r\n",
        "        return global_metrics, detailed_results_df\r\n",
        "    \r\n",
        "model_evaluator = ModelEvaluator()    "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCxHCGo8iJhh"
      },
      "source": [
        "#Popularity model\r\n",
        "\r\n",
        "\r\n",
        "A common (and usually hard-to-beat) baseline approach is the Popularity model. This model is not actually personalized - it simply recommends to a user the most popular items that the user has not previously consumed. As the popularity accounts for the \"wisdom of the crowds\", it usually provides good recommendations, generally interesting for most people.\r\n",
        "Ps. The main objective of a recommender system is to leverage the long-tail items to the users with very specific interests, which goes far beyond this simple technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "0jIBTzlKiNfD",
        "outputId": "2c3693fe-fe97-4eed-b79a-aef3bad4ce85"
      },
      "source": [
        "#Computes the most popular items\r\n",
        "item_popularity_df = interactions_full_df.groupby('contentId')['eventStrength'].sum().sort_values(ascending=False).reset_index()\r\n",
        "item_popularity_df.head(10)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contentId</th>\n",
              "      <th>eventStrength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4029704725707465084</td>\n",
              "      <td>307.733799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6783772548752091658</td>\n",
              "      <td>233.762157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-133139342397538859</td>\n",
              "      <td>228.024567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8208801367848627943</td>\n",
              "      <td>197.107608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6843047699859121724</td>\n",
              "      <td>193.825208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8224860111193157980</td>\n",
              "      <td>189.044680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-2358756719610361882</td>\n",
              "      <td>183.110951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2581138407738454418</td>\n",
              "      <td>180.282876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7507067965574797372</td>\n",
              "      <td>179.094002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1469580151036142903</td>\n",
              "      <td>170.548969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             contentId  eventStrength\n",
              "0 -4029704725707465084     307.733799\n",
              "1 -6783772548752091658     233.762157\n",
              "2  -133139342397538859     228.024567\n",
              "3 -8208801367848627943     197.107608\n",
              "4 -6843047699859121724     193.825208\n",
              "5  8224860111193157980     189.044680\n",
              "6 -2358756719610361882     183.110951\n",
              "7  2581138407738454418     180.282876\n",
              "8  7507067965574797372     179.094002\n",
              "9  1469580151036142903     170.548969"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrJOU_YviZ5G"
      },
      "source": [
        "class PopularityRecommender:\r\n",
        "    \r\n",
        "    MODEL_NAME = 'Popularity'\r\n",
        "    \r\n",
        "    def __init__(self, popularity_df, items_df=None):\r\n",
        "        self.popularity_df = popularity_df\r\n",
        "        self.items_df = items_df\r\n",
        "        \r\n",
        "    def get_model_name(self):\r\n",
        "        return self.MODEL_NAME\r\n",
        "        \r\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\r\n",
        "        # Recommend the more popular items that the user hasn't seen yet.\r\n",
        "        recommendations_df = self.popularity_df[~self.popularity_df['contentId'].isin(items_to_ignore)] \\\r\n",
        "                               .sort_values('eventStrength', ascending = False) \\\r\n",
        "                               .head(topn)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            if self.items_df is None:\r\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\r\n",
        "\r\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \r\n",
        "                                                          left_on = 'contentId', \r\n",
        "                                                          right_on = 'contentId')[['eventStrength', 'contentId', 'title', 'url', 'lang']]\r\n",
        "\r\n",
        "\r\n",
        "        return recommendations_df\r\n",
        "    \r\n",
        "popularity_model = PopularityRecommender(item_popularity_df, articles_df)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukBSajtwicwU"
      },
      "source": [
        "Here we perform the evaluation of the Popularity model, according to the method described above.\r\n",
        "It achieved the Recall@5 of 0.2417, which means that about 24% of interacted items in test set were ranked by Popularity model among the top-5 items (from lists with 100 random items). And Recall@10 was even higher (37%), as expected.\r\n",
        "It might be surprising to you that usually Popularity models could perform so well!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "4qqs-HgVidVl",
        "outputId": "5f7cffc7-39fa-489a-94d5-3ca193d18954"
      },
      "source": [
        "print('Evaluating Popularity recommendation model...')\r\n",
        "pop_global_metrics, pop_detailed_results_df = model_evaluator.evaluate_model(popularity_model)\r\n",
        "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\r\n",
        "pop_detailed_results_df.head(10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Popularity recommendation model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Popularity', 'recall@5': 0.2418818716440808, 'recall@10': 0.3725389925850166}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>_person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>28</td>\n",
              "      <td>50</td>\n",
              "      <td>192</td>\n",
              "      <td>0.145833</td>\n",
              "      <td>0.260417</td>\n",
              "      <td>3609194402293569455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>134</td>\n",
              "      <td>0.089552</td>\n",
              "      <td>0.186567</td>\n",
              "      <td>-2626634673110551643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>130</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.176923</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>117</td>\n",
              "      <td>0.042735</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>-1443636648652872475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>26</td>\n",
              "      <td>40</td>\n",
              "      <td>88</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>-2979881261169775358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>80</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>-3596626804281480007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>20</td>\n",
              "      <td>34</td>\n",
              "      <td>73</td>\n",
              "      <td>0.273973</td>\n",
              "      <td>0.465753</td>\n",
              "      <td>1116121227607581999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>69</td>\n",
              "      <td>0.246377</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>692689608292948411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>69</td>\n",
              "      <td>0.202899</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>-9016528795238256703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>21</td>\n",
              "      <td>28</td>\n",
              "      <td>68</td>\n",
              "      <td>0.308824</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>3636910968448833585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     hits@5_count  hits@10_count  ...  recall@10           _person_id\n",
              "76             28             50  ...   0.260417  3609194402293569455\n",
              "17             12             25  ...   0.186567 -2626634673110551643\n",
              "16             13             23  ...   0.176923 -1032019229384696495\n",
              "10              5              9  ...   0.076923 -1443636648652872475\n",
              "82             26             40  ...   0.454545 -2979881261169775358\n",
              "161            12             18  ...   0.225000 -3596626804281480007\n",
              "65             20             34  ...   0.465753  1116121227607581999\n",
              "81             17             23  ...   0.333333   692689608292948411\n",
              "106            14             18  ...   0.260870 -9016528795238256703\n",
              "52             21             28  ...   0.411765  3636910968448833585\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_twi2aGJi-v2"
      },
      "source": [
        "#Content-Based Filtering model\r\n",
        "\r\n",
        "Content-based filtering approaches leverage description or attributes from items the user has interacted to recommend similar items. It depends only on the user previous choices, making this method robust to avoid the cold-start problem. For textual items, like articles, news and books, it is simple to use the raw text to build item profiles and user profiles.\r\n",
        "Here we are using a very popular technique in information retrieval (search engines) named TF-IDF. This technique converts unstructured text into a vector structure, where each word is represented by a position in the vector, and the value measures how relevant a given word is for an article. As all items will be represented in the same Vector Space Model, it is to compute similarity between articles.\r\n",
        "See this presentation (from slide 30) for more information on TF-IDF and Cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFEYMv7bjA8f",
        "outputId": "eccd92f1-a1b1-41d7-8359-9a939fc78537"
      },
      "source": [
        "#Ignoring stopwords (words with no semantics) from English and Portuguese (as we have a corpus with mixed languages)\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "stopwords_list = stopwords.words('english') + stopwords.words('portuguese')\r\n",
        "\r\n",
        "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\r\n",
        "vectorizer = TfidfVectorizer(analyzer='word',\r\n",
        "                     ngram_range=(1, 2),\r\n",
        "                     min_df=0.003,\r\n",
        "                     max_df=0.5,\r\n",
        "                     max_features=5000,\r\n",
        "                     stop_words=stopwords_list)\r\n",
        "\r\n",
        "item_ids = articles_df['contentId'].tolist()\r\n",
        "tfidf_matrix = vectorizer.fit_transform(articles_df['title'] + \"\" + articles_df['text'])\r\n",
        "tfidf_feature_names = vectorizer.get_feature_names()\r\n",
        "tfidf_matrix"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3047x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 638928 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX7P9Bqbj9J2"
      },
      "source": [
        "To model the user profile, we take all the item profiles the user has interacted and average them. The average is weighted by the interaction strength, in other words, the articles the user has interacted the most (eg. liked or commented) will have a higher strength in the final user profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22in-Q0Nj9tg"
      },
      "source": [
        "def get_item_profile(item_id):\r\n",
        "    idx = item_ids.index(item_id)\r\n",
        "    item_profile = tfidf_matrix[idx:idx+1]\r\n",
        "    return item_profile\r\n",
        "\r\n",
        "def get_item_profiles(ids):\r\n",
        "    item_profiles_list = [get_item_profile(x) for x in ids]\r\n",
        "    item_profiles = scipy.sparse.vstack(item_profiles_list)\r\n",
        "    return item_profiles\r\n",
        "\r\n",
        "def build_users_profile(person_id, interactions_indexed_df):\r\n",
        "    interactions_person_df = interactions_indexed_df.loc[person_id]\r\n",
        "    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\r\n",
        "    \r\n",
        "    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\r\n",
        "    #Weighted average of item profiles by the interactions strength\r\n",
        "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\r\n",
        "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\r\n",
        "    return user_profile_norm\r\n",
        "\r\n",
        "def build_users_profiles(): \r\n",
        "    interactions_indexed_df = interactions_train_df[interactions_train_df['contentId'] \\\r\n",
        "                                                   .isin(articles_df['contentId'])].set_index('personId')\r\n",
        "    user_profiles = {}\r\n",
        "    for person_id in interactions_indexed_df.index.unique():\r\n",
        "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\r\n",
        "    return user_profiles"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XL9H8ktkEri",
        "outputId": "a697c0f6-4ffb-4031-b801-310031b2d44d"
      },
      "source": [
        "user_profiles = build_users_profiles()\r\n",
        "len(user_profiles)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vja2PY1ikj2d"
      },
      "source": [
        "Let's take a look in the profile. It is a unit vector of 5000 length. The value in each position represents how relevant is a token (unigram or bigram) for me.\r\n",
        "Looking my profile, it appears that the top relevant tokens really represent my professional interests in machine learning, deep learning, artificial intelligence and google cloud platform! So we might expect good recommendations here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "xhi-eaPnkknj",
        "outputId": "becd0ac1-9497-46c5-984b-a2a0cc295d8f"
      },
      "source": [
        "myprofile = user_profiles[-1479311724257856983]\r\n",
        "print(myprofile.shape)\r\n",
        "pd.DataFrame(sorted(zip(tfidf_feature_names, \r\n",
        "                        user_profiles[-1479311724257856983].flatten().tolist()), key=lambda x: -x[1])[:20],\r\n",
        "             columns=['token', 'relevance'])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>learning</td>\n",
              "      <td>0.298732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>machine learning</td>\n",
              "      <td>0.245992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machine</td>\n",
              "      <td>0.237843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>google</td>\n",
              "      <td>0.202839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data</td>\n",
              "      <td>0.169776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ai</td>\n",
              "      <td>0.156203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>algorithms</td>\n",
              "      <td>0.115666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>like</td>\n",
              "      <td>0.097744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>language</td>\n",
              "      <td>0.087609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>people</td>\n",
              "      <td>0.082024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>deep</td>\n",
              "      <td>0.081542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>deep learning</td>\n",
              "      <td>0.080979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>research</td>\n",
              "      <td>0.076020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>algorithm</td>\n",
              "      <td>0.074905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>apple</td>\n",
              "      <td>0.074050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>intelligence</td>\n",
              "      <td>0.072663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>use</td>\n",
              "      <td>0.072597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>human</td>\n",
              "      <td>0.072494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>models</td>\n",
              "      <td>0.072388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>artificial</td>\n",
              "      <td>0.072062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               token  relevance\n",
              "0           learning   0.298732\n",
              "1   machine learning   0.245992\n",
              "2            machine   0.237843\n",
              "3             google   0.202839\n",
              "4               data   0.169776\n",
              "5                 ai   0.156203\n",
              "6         algorithms   0.115666\n",
              "7               like   0.097744\n",
              "8           language   0.087609\n",
              "9             people   0.082024\n",
              "10              deep   0.081542\n",
              "11     deep learning   0.080979\n",
              "12          research   0.076020\n",
              "13         algorithm   0.074905\n",
              "14             apple   0.074050\n",
              "15      intelligence   0.072663\n",
              "16               use   0.072597\n",
              "17             human   0.072494\n",
              "18            models   0.072388\n",
              "19        artificial   0.072062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWNlCVuCkr1h"
      },
      "source": [
        "class ContentBasedRecommender:\r\n",
        "    \r\n",
        "    MODEL_NAME = 'Content-Based'\r\n",
        "    \r\n",
        "    def __init__(self, items_df=None):\r\n",
        "        self.item_ids = item_ids\r\n",
        "        self.items_df = items_df\r\n",
        "        \r\n",
        "    def get_model_name(self):\r\n",
        "        return self.MODEL_NAME\r\n",
        "        \r\n",
        "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\r\n",
        "        #Computes the cosine similarity between the user profile and all item profiles\r\n",
        "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\r\n",
        "        #Gets the top similar items\r\n",
        "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\r\n",
        "        #Sort the similar items by similarity\r\n",
        "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\r\n",
        "        return similar_items\r\n",
        "        \r\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\r\n",
        "        similar_items = self._get_similar_items_to_user_profile(user_id)\r\n",
        "        #Ignores items the user has already interacted\r\n",
        "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\r\n",
        "        \r\n",
        "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength']) \\\r\n",
        "                                    .head(topn)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            if self.items_df is None:\r\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\r\n",
        "\r\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \r\n",
        "                                                          left_on = 'contentId', \r\n",
        "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\r\n",
        "\r\n",
        "\r\n",
        "        return recommendations_df\r\n",
        "    \r\n",
        "content_based_recommender_model = ContentBasedRecommender(articles_df)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TrehmNJkvhk"
      },
      "source": [
        "With personalized recommendations of content-based filtering model, we have a Recall@5 to about 0.162, which means that about 16% of interacted items in test set were ranked by this model among the top-5 items (from lists with 100 random items). And Recall@10 was 0.261 (52%). The lower performance of the Content-Based model compared to the Popularity model may indicate that users are not that fixed in content very similar to their previous reads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "99ooKtI_kwir",
        "outputId": "c58ff606-d18c-4e8b-f62f-9c9d72286b7d"
      },
      "source": [
        "print('Evaluating Content-Based Filtering model...')\r\n",
        "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\r\n",
        "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\r\n",
        "cb_detailed_results_df.head(10)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Content-Based Filtering model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Content-Based', 'recall@5': 0.16287394528253643, 'recall@10': 0.2614420864229097}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>_person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "      <td>192</td>\n",
              "      <td>0.078125</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>3609194402293569455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>29</td>\n",
              "      <td>134</td>\n",
              "      <td>0.134328</td>\n",
              "      <td>0.216418</td>\n",
              "      <td>-2626634673110551643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20</td>\n",
              "      <td>33</td>\n",
              "      <td>130</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.253846</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>32</td>\n",
              "      <td>47</td>\n",
              "      <td>117</td>\n",
              "      <td>0.273504</td>\n",
              "      <td>0.401709</td>\n",
              "      <td>-1443636648652872475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>88</td>\n",
              "      <td>0.068182</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>-2979881261169775358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>80</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.287500</td>\n",
              "      <td>-3596626804281480007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>73</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>1116121227607581999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>69</td>\n",
              "      <td>0.115942</td>\n",
              "      <td>0.275362</td>\n",
              "      <td>692689608292948411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>69</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>-9016528795238256703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>68</td>\n",
              "      <td>0.044118</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>3636910968448833585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     hits@5_count  hits@10_count  ...  recall@10           _person_id\n",
              "76             15             24  ...   0.125000  3609194402293569455\n",
              "17             18             29  ...   0.216418 -2626634673110551643\n",
              "16             20             33  ...   0.253846 -1032019229384696495\n",
              "10             32             47  ...   0.401709 -1443636648652872475\n",
              "82              6             15  ...   0.170455 -2979881261169775358\n",
              "161            11             23  ...   0.287500 -3596626804281480007\n",
              "65              8             13  ...   0.178082  1116121227607581999\n",
              "81              8             19  ...   0.275362   692689608292948411\n",
              "106             3              9  ...   0.130435 -9016528795238256703\n",
              "52              3              8  ...   0.117647  3636910968448833585\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXzcEJ0clkU6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBR3ZhlDk3l5"
      },
      "source": [
        "#Collaborative Filtering model\r\n",
        "\r\n",
        "Collaborative Filtering (CF) has two main implementation strategies:\r\n",
        "\r\n",
        "Memory-based: This approach uses the memory of previous users interactions to compute users similarities based on items they've interacted (user-based approach) or compute items similarities based on the users that have interacted with them (item-based approach).\r\n",
        "A typical example of this approach is User Neighbourhood-based CF, in which the top-N similar users (usually computed using Pearson correlation) for a user are selected and used to recommend items those similar users liked, but the current user have not interacted yet. This approach is very simple to implement, but usually do not scale well for many users. A nice Python implementation of this approach in available in Crab.\r\n",
        "Model-based: This approach, models are developed using different machine learning algorithms to recommend items to users. There are many model-based CF algorithms, like neural networks, bayesian networks, clustering models, and latent factor models such as Singular Value Decomposition (SVD) and, probabilistic latent semantic analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lcp8je-k8-f"
      },
      "source": [
        "#Matrix Factorization\r\n",
        "\r\n",
        "Latent factor models compress user-item matrix into a low-dimensional representation in terms of latent factors. One advantage of using this approach is that instead of having a high dimensional matrix containing abundant number of missing values we will be dealing with a much smaller matrix in lower-dimensional space.\r\n",
        "A reduced presentation could be utilized for either user-based or item-based neighborhood algorithms that are presented in the previous section. There are several advantages with this paradigm. It handles the sparsity of the original matrix better than memory based ones. Also comparing similarity on the resulting matrix is much more scalable especially in dealing with large sparse datasets.\r\n",
        "\r\n",
        "Here we a use popular latent factor model named Singular Value Decomposition (SVD). There are other matrix factorization frameworks more specific to CF you might try, like surprise, mrec or python-recsys. We chose a SciPy implemenation of SVD because it is available on Kaggle kernels. P.s. See an example of SVD on a movies dataset in this blog post.\r\n",
        "\r\n",
        "An important decision is the number of factors to factor the user-item matrix. The higher the number of factors, the more precise is the factorization in the original matrix reconstructions. Therefore, if the model is allowed to memorize too much details of the original matrix, it may not generalize well for data it was not trained on. Reducing the number of factors increases the model generalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "teTPBR39lApD",
        "outputId": "2edba6b1-976c-4f42-e2f6-03b6f45176cb"
      },
      "source": [
        "#Creating a sparse pivot table with users in rows and items in columns\r\n",
        "users_items_pivot_matrix_df = interactions_train_df.pivot(index='personId', \r\n",
        "                                                          columns='contentId', \r\n",
        "                                                          values='eventStrength').fillna(0)\r\n",
        "\r\n",
        "users_items_pivot_matrix_df.head(10)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>contentId</th>\n",
              "      <th>-9222795471790223670</th>\n",
              "      <th>-9216926795620865886</th>\n",
              "      <th>-9194572880052200111</th>\n",
              "      <th>-9192549002213406534</th>\n",
              "      <th>-9190737901804729417</th>\n",
              "      <th>-9189659052158407108</th>\n",
              "      <th>-9176143510534135851</th>\n",
              "      <th>-9172673334835262304</th>\n",
              "      <th>-9171475473795142532</th>\n",
              "      <th>-9166778629773133902</th>\n",
              "      <th>-9161596996229760398</th>\n",
              "      <th>-9160910454530522563</th>\n",
              "      <th>-9157338616628196758</th>\n",
              "      <th>-9153494109165200346</th>\n",
              "      <th>-9147114693160126293</th>\n",
              "      <th>-9137036168156595470</th>\n",
              "      <th>-9128741757954228992</th>\n",
              "      <th>-9128652074338368262</th>\n",
              "      <th>-9107331682787867601</th>\n",
              "      <th>-9105040345021932755</th>\n",
              "      <th>-9103776596534246502</th>\n",
              "      <th>-9102431381393428051</th>\n",
              "      <th>-9100490342054218852</th>\n",
              "      <th>-9099155556042679205</th>\n",
              "      <th>-9095002324981651252</th>\n",
              "      <th>-9092333155845304874</th>\n",
              "      <th>-9090514312860140897</th>\n",
              "      <th>-9089854794058353436</th>\n",
              "      <th>-9086955082453789880</th>\n",
              "      <th>-9083294960368598209</th>\n",
              "      <th>-9081753261356157170</th>\n",
              "      <th>-9080873096647717414</th>\n",
              "      <th>-9076501258717815738</th>\n",
              "      <th>-9073210245497295284</th>\n",
              "      <th>-9071883412530082330</th>\n",
              "      <th>-9064100704535292718</th>\n",
              "      <th>-9056114023474725450</th>\n",
              "      <th>-9055044275358686874</th>\n",
              "      <th>-9050450867630628092</th>\n",
              "      <th>-9045753673721269477</th>\n",
              "      <th>...</th>\n",
              "      <th>8962537427807366481</th>\n",
              "      <th>8963770574956550187</th>\n",
              "      <th>8963938873430212934</th>\n",
              "      <th>8968837261991914049</th>\n",
              "      <th>8969476626572775042</th>\n",
              "      <th>8974280745225397183</th>\n",
              "      <th>8982094176562780806</th>\n",
              "      <th>8993230615635349817</th>\n",
              "      <th>9004099881383415529</th>\n",
              "      <th>9026402401132606773</th>\n",
              "      <th>9028580484484026894</th>\n",
              "      <th>9032993320407723266</th>\n",
              "      <th>9033884391004475493</th>\n",
              "      <th>9038543365726770177</th>\n",
              "      <th>9042192299854648021</th>\n",
              "      <th>9045808098977760576</th>\n",
              "      <th>9054050762437897017</th>\n",
              "      <th>9056727675613132316</th>\n",
              "      <th>9060231864899459154</th>\n",
              "      <th>9079880752026843473</th>\n",
              "      <th>9091641298512813712</th>\n",
              "      <th>9112765177685685246</th>\n",
              "      <th>9121100366909552616</th>\n",
              "      <th>9122627895188486603</th>\n",
              "      <th>9124439338148818380</th>\n",
              "      <th>9128267824356972069</th>\n",
              "      <th>9136323715291453594</th>\n",
              "      <th>9151634133568930081</th>\n",
              "      <th>9168028029170358424</th>\n",
              "      <th>9175693555063886126</th>\n",
              "      <th>9191014301634017491</th>\n",
              "      <th>9207286802575546269</th>\n",
              "      <th>9208127165664287660</th>\n",
              "      <th>9209629151177723638</th>\n",
              "      <th>9209886322932807692</th>\n",
              "      <th>9213260650272029784</th>\n",
              "      <th>9215261273565326920</th>\n",
              "      <th>9217155070834564627</th>\n",
              "      <th>9220445660318725468</th>\n",
              "      <th>9222265156747237864</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-9223121837663643404</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9212075797126931087</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9207251133131336884</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9199575329909162940</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9196668942822132778</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9188188261933657343</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9172914609055320039</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.584963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9156344805277471150</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9120685872592674274</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9109785559521267180</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã 2926 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "contentId             -9222795471790223670  ...   9222265156747237864\n",
              "personId                                    ...                      \n",
              "-9223121837663643404                   0.0  ...                   0.0\n",
              "-9212075797126931087                   0.0  ...                   0.0\n",
              "-9207251133131336884                   0.0  ...                   0.0\n",
              "-9199575329909162940                   0.0  ...                   0.0\n",
              "-9196668942822132778                   0.0  ...                   0.0\n",
              "-9188188261933657343                   0.0  ...                   0.0\n",
              "-9172914609055320039                   0.0  ...                   0.0\n",
              "-9156344805277471150                   0.0  ...                   0.0\n",
              "-9120685872592674274                   0.0  ...                   0.0\n",
              "-9109785559521267180                   0.0  ...                   0.0\n",
              "\n",
              "[10 rows x 2926 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcVRNBD2llwX",
        "outputId": "9a7536e2-a769-4ac7-e3d1-0d50b24b4ea5"
      },
      "source": [
        "users_items_pivot_matrix = users_items_pivot_matrix_df.to_numpy()\r\n",
        "users_items_pivot_matrix[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 2., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pnBaMUYnnzk",
        "outputId": "6be95c9a-89fe-47c7-e690-edf48fba00ac"
      },
      "source": [
        "users_ids = list(users_items_pivot_matrix_df.index)\r\n",
        "users_ids[:10]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-9223121837663643404,\n",
              " -9212075797126931087,\n",
              " -9207251133131336884,\n",
              " -9199575329909162940,\n",
              " -9196668942822132778,\n",
              " -9188188261933657343,\n",
              " -9172914609055320039,\n",
              " -9156344805277471150,\n",
              " -9120685872592674274,\n",
              " -9109785559521267180]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaRrMHF8nqbr",
        "outputId": "fa6e06f5-ff90-4b03-fd5f-4cb1b46e0058"
      },
      "source": [
        "users_items_pivot_sparse_matrix = csr_matrix(users_items_pivot_matrix)\r\n",
        "users_items_pivot_sparse_matrix"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1140x2926 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 31284 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb6aAUqwntVP"
      },
      "source": [
        "#The number of factors to factor the user-item matrix.\r\n",
        "NUMBER_OF_FACTORS_MF = 15\r\n",
        "#Performs matrix factorization of the original user item matrix\r\n",
        "#U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)\r\n",
        "U, sigma, Vt = svds(users_items_pivot_sparse_matrix, k = NUMBER_OF_FACTORS_MF)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYa499alnwJG",
        "outputId": "3ff41e40-f45f-4c37-da53-c83e22cf57ae"
      },
      "source": [
        "U.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1140, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI6VnOl2nxzu",
        "outputId": "5dc71fa0-9224-4427-b4b4-80ece5a8b555"
      },
      "source": [
        "Vt.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 2926)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRsGat3enzTd",
        "outputId": "1cf42444-d699-4733-a216-5a431c33da48"
      },
      "source": [
        "sigma = np.diag(sigma)\r\n",
        "sigma.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePexk9Rhn3st"
      },
      "source": [
        "After the factorization, we try to to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It was generated predictions for items the user have not yet interaction, which we will exploit for recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIHSlEmRn4bJ",
        "outputId": "43ed45ca-3217-4b97-c159-680430c3d038"
      },
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \r\n",
        "all_user_predicted_ratings"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01039915,  0.00081872, -0.01725263, ...,  0.00140708,\n",
              "         0.0110647 ,  0.00226063],\n",
              "       [-0.00019285, -0.00031318, -0.00264624, ...,  0.00251658,\n",
              "         0.00017609, -0.00189488],\n",
              "       [-0.01254721,  0.0065947 , -0.00590676, ...,  0.00698975,\n",
              "        -0.01015696,  0.01154572],\n",
              "       ...,\n",
              "       [-0.02995379,  0.00805715, -0.01846307, ..., -0.01083078,\n",
              "        -0.00118591,  0.0096798 ],\n",
              "       [-0.01845505,  0.00467019,  0.01219602, ...,  0.00409507,\n",
              "         0.00019482, -0.00752562],\n",
              "       [-0.01506374,  0.00327732,  0.13391269, ..., -0.01191815,\n",
              "         0.06422074,  0.01303244]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvgu3JcPn9C_"
      },
      "source": [
        "all_user_predicted_ratings_norm = (all_user_predicted_ratings - all_user_predicted_ratings.min()) / (all_user_predicted_ratings.max() - all_user_predicted_ratings.min())"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "DwfXpOi7n-Ym",
        "outputId": "f2491c9d-c6aa-4c4e-b9de-c90ac4e7f864"
      },
      "source": [
        "#Converting the reconstructed matrix back to a Pandas dataframe\r\n",
        "cf_preds_df = pd.DataFrame(all_user_predicted_ratings_norm, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\r\n",
        "cf_preds_df.head(10)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-9223121837663643404</th>\n",
              "      <th>-9212075797126931087</th>\n",
              "      <th>-9207251133131336884</th>\n",
              "      <th>-9199575329909162940</th>\n",
              "      <th>-9196668942822132778</th>\n",
              "      <th>-9188188261933657343</th>\n",
              "      <th>-9172914609055320039</th>\n",
              "      <th>-9156344805277471150</th>\n",
              "      <th>-9120685872592674274</th>\n",
              "      <th>-9109785559521267180</th>\n",
              "      <th>-9063420486253202900</th>\n",
              "      <th>-9060214117327732109</th>\n",
              "      <th>-9047547311469006438</th>\n",
              "      <th>-9016528795238256703</th>\n",
              "      <th>-9009798162809551896</th>\n",
              "      <th>-9001583565812478106</th>\n",
              "      <th>-8994220765455693336</th>\n",
              "      <th>-8909668725653743114</th>\n",
              "      <th>-8891033171626175843</th>\n",
              "      <th>-8860671864164757449</th>\n",
              "      <th>-8854674432071487111</th>\n",
              "      <th>-8853658195208337106</th>\n",
              "      <th>-8845298781299428018</th>\n",
              "      <th>-8830250090736356260</th>\n",
              "      <th>-8823950498314351783</th>\n",
              "      <th>-8802075878443651241</th>\n",
              "      <th>-8784674845716296727</th>\n",
              "      <th>-8781635134606732409</th>\n",
              "      <th>-8781306637602263252</th>\n",
              "      <th>-8763398617720485024</th>\n",
              "      <th>-8738496712327699923</th>\n",
              "      <th>-8719462623048086192</th>\n",
              "      <th>-8704807962619440953</th>\n",
              "      <th>-8699750646678621887</th>\n",
              "      <th>-8694104221113176052</th>\n",
              "      <th>-8686631410634491662</th>\n",
              "      <th>-8674958742744576254</th>\n",
              "      <th>-8672331451814079632</th>\n",
              "      <th>-8670749047273764903</th>\n",
              "      <th>-8652741825481604192</th>\n",
              "      <th>...</th>\n",
              "      <th>8791271631167250981</th>\n",
              "      <th>8801420707973230165</th>\n",
              "      <th>8801970869404590779</th>\n",
              "      <th>8813266398846460512</th>\n",
              "      <th>8841741572929644986</th>\n",
              "      <th>8847054836611412804</th>\n",
              "      <th>8855523843512271162</th>\n",
              "      <th>8862260182894039021</th>\n",
              "      <th>8872819156169667456</th>\n",
              "      <th>8874741321583329336</th>\n",
              "      <th>8879844298911979276</th>\n",
              "      <th>8892482595912468268</th>\n",
              "      <th>8907499588729810535</th>\n",
              "      <th>8913362709216003291</th>\n",
              "      <th>8920667914865172372</th>\n",
              "      <th>8940614478925413056</th>\n",
              "      <th>8941502917401491878</th>\n",
              "      <th>8961723342122872302</th>\n",
              "      <th>8965285988346645117</th>\n",
              "      <th>8968131284214320024</th>\n",
              "      <th>8982783231149017560</th>\n",
              "      <th>8992729171160464416</th>\n",
              "      <th>9013651444868609421</th>\n",
              "      <th>9033898219489253274</th>\n",
              "      <th>9037410398700100618</th>\n",
              "      <th>9038446466275805109</th>\n",
              "      <th>9050204922960952289</th>\n",
              "      <th>9090527742744334314</th>\n",
              "      <th>9091970136990402395</th>\n",
              "      <th>9102085903669288476</th>\n",
              "      <th>9105269044962898535</th>\n",
              "      <th>9109075639526981934</th>\n",
              "      <th>9135582630122950040</th>\n",
              "      <th>9137372837662939523</th>\n",
              "      <th>9148269800512008413</th>\n",
              "      <th>9165571805999894845</th>\n",
              "      <th>9187866633451383747</th>\n",
              "      <th>9191849144618614467</th>\n",
              "      <th>9199170757466086545</th>\n",
              "      <th>9210530975708218054</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contentId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-9222795471790223670</th>\n",
              "      <td>0.139129</td>\n",
              "      <td>0.137930</td>\n",
              "      <td>0.136531</td>\n",
              "      <td>0.143948</td>\n",
              "      <td>0.136815</td>\n",
              "      <td>0.137339</td>\n",
              "      <td>0.137508</td>\n",
              "      <td>0.143534</td>\n",
              "      <td>0.136428</td>\n",
              "      <td>0.135681</td>\n",
              "      <td>0.136873</td>\n",
              "      <td>0.138129</td>\n",
              "      <td>0.136588</td>\n",
              "      <td>0.130577</td>\n",
              "      <td>0.150717</td>\n",
              "      <td>0.142606</td>\n",
              "      <td>0.136765</td>\n",
              "      <td>0.137352</td>\n",
              "      <td>0.134002</td>\n",
              "      <td>0.124023</td>\n",
              "      <td>0.136944</td>\n",
              "      <td>0.133141</td>\n",
              "      <td>0.185105</td>\n",
              "      <td>0.134144</td>\n",
              "      <td>0.137539</td>\n",
              "      <td>0.137903</td>\n",
              "      <td>0.137115</td>\n",
              "      <td>0.137101</td>\n",
              "      <td>0.138658</td>\n",
              "      <td>0.144550</td>\n",
              "      <td>0.134712</td>\n",
              "      <td>0.142815</td>\n",
              "      <td>0.137962</td>\n",
              "      <td>0.137030</td>\n",
              "      <td>0.153129</td>\n",
              "      <td>0.137575</td>\n",
              "      <td>0.141602</td>\n",
              "      <td>0.134200</td>\n",
              "      <td>0.133515</td>\n",
              "      <td>0.138167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137972</td>\n",
              "      <td>0.140265</td>\n",
              "      <td>0.135848</td>\n",
              "      <td>0.140562</td>\n",
              "      <td>0.135223</td>\n",
              "      <td>0.137119</td>\n",
              "      <td>0.139497</td>\n",
              "      <td>0.135881</td>\n",
              "      <td>0.136262</td>\n",
              "      <td>0.136875</td>\n",
              "      <td>0.135751</td>\n",
              "      <td>0.137961</td>\n",
              "      <td>0.137583</td>\n",
              "      <td>0.137657</td>\n",
              "      <td>0.138469</td>\n",
              "      <td>0.136019</td>\n",
              "      <td>0.138092</td>\n",
              "      <td>0.137739</td>\n",
              "      <td>0.137670</td>\n",
              "      <td>0.195783</td>\n",
              "      <td>0.137108</td>\n",
              "      <td>0.135888</td>\n",
              "      <td>0.137397</td>\n",
              "      <td>0.136848</td>\n",
              "      <td>0.138275</td>\n",
              "      <td>0.138327</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.137248</td>\n",
              "      <td>0.139015</td>\n",
              "      <td>0.141458</td>\n",
              "      <td>0.137351</td>\n",
              "      <td>0.127822</td>\n",
              "      <td>0.137946</td>\n",
              "      <td>0.139653</td>\n",
              "      <td>0.140324</td>\n",
              "      <td>0.136888</td>\n",
              "      <td>0.135787</td>\n",
              "      <td>0.134560</td>\n",
              "      <td>0.135862</td>\n",
              "      <td>0.136246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9216926795620865886</th>\n",
              "      <td>0.138044</td>\n",
              "      <td>0.137916</td>\n",
              "      <td>0.138698</td>\n",
              "      <td>0.137878</td>\n",
              "      <td>0.137969</td>\n",
              "      <td>0.137990</td>\n",
              "      <td>0.137974</td>\n",
              "      <td>0.138049</td>\n",
              "      <td>0.138217</td>\n",
              "      <td>0.138151</td>\n",
              "      <td>0.138030</td>\n",
              "      <td>0.137906</td>\n",
              "      <td>0.137802</td>\n",
              "      <td>0.139819</td>\n",
              "      <td>0.139060</td>\n",
              "      <td>0.138581</td>\n",
              "      <td>0.138495</td>\n",
              "      <td>0.138178</td>\n",
              "      <td>0.138921</td>\n",
              "      <td>0.142132</td>\n",
              "      <td>0.138560</td>\n",
              "      <td>0.140137</td>\n",
              "      <td>0.136909</td>\n",
              "      <td>0.137947</td>\n",
              "      <td>0.138055</td>\n",
              "      <td>0.138029</td>\n",
              "      <td>0.138159</td>\n",
              "      <td>0.137973</td>\n",
              "      <td>0.138319</td>\n",
              "      <td>0.139002</td>\n",
              "      <td>0.138095</td>\n",
              "      <td>0.138327</td>\n",
              "      <td>0.137942</td>\n",
              "      <td>0.138777</td>\n",
              "      <td>0.138120</td>\n",
              "      <td>0.137983</td>\n",
              "      <td>0.138999</td>\n",
              "      <td>0.138718</td>\n",
              "      <td>0.139083</td>\n",
              "      <td>0.137882</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138007</td>\n",
              "      <td>0.138102</td>\n",
              "      <td>0.137982</td>\n",
              "      <td>0.138226</td>\n",
              "      <td>0.138274</td>\n",
              "      <td>0.137751</td>\n",
              "      <td>0.138323</td>\n",
              "      <td>0.138471</td>\n",
              "      <td>0.138529</td>\n",
              "      <td>0.137938</td>\n",
              "      <td>0.138427</td>\n",
              "      <td>0.138162</td>\n",
              "      <td>0.138104</td>\n",
              "      <td>0.137846</td>\n",
              "      <td>0.139777</td>\n",
              "      <td>0.138316</td>\n",
              "      <td>0.138128</td>\n",
              "      <td>0.138197</td>\n",
              "      <td>0.138029</td>\n",
              "      <td>0.140776</td>\n",
              "      <td>0.137905</td>\n",
              "      <td>0.138269</td>\n",
              "      <td>0.137898</td>\n",
              "      <td>0.138227</td>\n",
              "      <td>0.137861</td>\n",
              "      <td>0.138231</td>\n",
              "      <td>0.138039</td>\n",
              "      <td>0.137939</td>\n",
              "      <td>0.138106</td>\n",
              "      <td>0.137890</td>\n",
              "      <td>0.137962</td>\n",
              "      <td>0.139527</td>\n",
              "      <td>0.138009</td>\n",
              "      <td>0.138117</td>\n",
              "      <td>0.139634</td>\n",
              "      <td>0.138058</td>\n",
              "      <td>0.138222</td>\n",
              "      <td>0.138864</td>\n",
              "      <td>0.138480</td>\n",
              "      <td>0.138323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9194572880052200111</th>\n",
              "      <td>0.135998</td>\n",
              "      <td>0.137652</td>\n",
              "      <td>0.137283</td>\n",
              "      <td>0.137536</td>\n",
              "      <td>0.140363</td>\n",
              "      <td>0.137807</td>\n",
              "      <td>0.141246</td>\n",
              "      <td>0.136284</td>\n",
              "      <td>0.135301</td>\n",
              "      <td>0.138512</td>\n",
              "      <td>0.140841</td>\n",
              "      <td>0.138711</td>\n",
              "      <td>0.139789</td>\n",
              "      <td>0.128246</td>\n",
              "      <td>0.144622</td>\n",
              "      <td>0.141345</td>\n",
              "      <td>0.137643</td>\n",
              "      <td>0.139323</td>\n",
              "      <td>0.137696</td>\n",
              "      <td>0.139703</td>\n",
              "      <td>0.137689</td>\n",
              "      <td>0.156370</td>\n",
              "      <td>0.125468</td>\n",
              "      <td>0.142828</td>\n",
              "      <td>0.138392</td>\n",
              "      <td>0.138221</td>\n",
              "      <td>0.140230</td>\n",
              "      <td>0.137840</td>\n",
              "      <td>0.148801</td>\n",
              "      <td>0.146963</td>\n",
              "      <td>0.136267</td>\n",
              "      <td>0.141754</td>\n",
              "      <td>0.138444</td>\n",
              "      <td>0.140615</td>\n",
              "      <td>0.131440</td>\n",
              "      <td>0.138559</td>\n",
              "      <td>0.147311</td>\n",
              "      <td>0.139779</td>\n",
              "      <td>0.147000</td>\n",
              "      <td>0.140466</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.139455</td>\n",
              "      <td>0.137283</td>\n",
              "      <td>0.136793</td>\n",
              "      <td>0.139520</td>\n",
              "      <td>0.139865</td>\n",
              "      <td>0.146728</td>\n",
              "      <td>0.137552</td>\n",
              "      <td>0.142963</td>\n",
              "      <td>0.139664</td>\n",
              "      <td>0.144436</td>\n",
              "      <td>0.141681</td>\n",
              "      <td>0.139307</td>\n",
              "      <td>0.139046</td>\n",
              "      <td>0.138571</td>\n",
              "      <td>0.135371</td>\n",
              "      <td>0.139288</td>\n",
              "      <td>0.138132</td>\n",
              "      <td>0.137715</td>\n",
              "      <td>0.149994</td>\n",
              "      <td>0.138013</td>\n",
              "      <td>0.139390</td>\n",
              "      <td>0.137086</td>\n",
              "      <td>0.137759</td>\n",
              "      <td>0.137799</td>\n",
              "      <td>0.140283</td>\n",
              "      <td>0.138518</td>\n",
              "      <td>0.138112</td>\n",
              "      <td>0.139763</td>\n",
              "      <td>0.136812</td>\n",
              "      <td>0.139257</td>\n",
              "      <td>0.143161</td>\n",
              "      <td>0.139139</td>\n",
              "      <td>0.140077</td>\n",
              "      <td>0.154976</td>\n",
              "      <td>0.140109</td>\n",
              "      <td>0.140654</td>\n",
              "      <td>0.135861</td>\n",
              "      <td>0.139332</td>\n",
              "      <td>0.153114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9192549002213406534</th>\n",
              "      <td>0.141924</td>\n",
              "      <td>0.137996</td>\n",
              "      <td>0.134663</td>\n",
              "      <td>0.137080</td>\n",
              "      <td>0.139946</td>\n",
              "      <td>0.138574</td>\n",
              "      <td>0.139473</td>\n",
              "      <td>0.144469</td>\n",
              "      <td>0.143333</td>\n",
              "      <td>0.138428</td>\n",
              "      <td>0.141432</td>\n",
              "      <td>0.137050</td>\n",
              "      <td>0.137440</td>\n",
              "      <td>0.253586</td>\n",
              "      <td>0.235253</td>\n",
              "      <td>0.152683</td>\n",
              "      <td>0.139437</td>\n",
              "      <td>0.138290</td>\n",
              "      <td>0.133682</td>\n",
              "      <td>0.162980</td>\n",
              "      <td>0.135424</td>\n",
              "      <td>0.163190</td>\n",
              "      <td>0.180049</td>\n",
              "      <td>0.147092</td>\n",
              "      <td>0.139735</td>\n",
              "      <td>0.137446</td>\n",
              "      <td>0.139441</td>\n",
              "      <td>0.139040</td>\n",
              "      <td>0.154785</td>\n",
              "      <td>0.149483</td>\n",
              "      <td>0.139090</td>\n",
              "      <td>0.134246</td>\n",
              "      <td>0.139747</td>\n",
              "      <td>0.135225</td>\n",
              "      <td>0.138831</td>\n",
              "      <td>0.140566</td>\n",
              "      <td>0.148091</td>\n",
              "      <td>0.134264</td>\n",
              "      <td>0.139635</td>\n",
              "      <td>0.144029</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138287</td>\n",
              "      <td>0.140515</td>\n",
              "      <td>0.142015</td>\n",
              "      <td>0.138465</td>\n",
              "      <td>0.142294</td>\n",
              "      <td>0.139936</td>\n",
              "      <td>0.151212</td>\n",
              "      <td>0.141403</td>\n",
              "      <td>0.144641</td>\n",
              "      <td>0.141462</td>\n",
              "      <td>0.152350</td>\n",
              "      <td>0.136734</td>\n",
              "      <td>0.139035</td>\n",
              "      <td>0.142453</td>\n",
              "      <td>0.133068</td>\n",
              "      <td>0.134365</td>\n",
              "      <td>0.140076</td>\n",
              "      <td>0.137809</td>\n",
              "      <td>0.138090</td>\n",
              "      <td>0.119932</td>\n",
              "      <td>0.138428</td>\n",
              "      <td>0.139932</td>\n",
              "      <td>0.139678</td>\n",
              "      <td>0.137343</td>\n",
              "      <td>0.136723</td>\n",
              "      <td>0.138767</td>\n",
              "      <td>0.138920</td>\n",
              "      <td>0.133864</td>\n",
              "      <td>0.135980</td>\n",
              "      <td>0.137682</td>\n",
              "      <td>0.140233</td>\n",
              "      <td>0.167426</td>\n",
              "      <td>0.138849</td>\n",
              "      <td>0.137037</td>\n",
              "      <td>0.141820</td>\n",
              "      <td>0.139260</td>\n",
              "      <td>0.139513</td>\n",
              "      <td>0.136804</td>\n",
              "      <td>0.140862</td>\n",
              "      <td>0.148793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9190737901804729417</th>\n",
              "      <td>0.140209</td>\n",
              "      <td>0.137408</td>\n",
              "      <td>0.138708</td>\n",
              "      <td>0.138672</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.138218</td>\n",
              "      <td>0.138390</td>\n",
              "      <td>0.138418</td>\n",
              "      <td>0.134883</td>\n",
              "      <td>0.140193</td>\n",
              "      <td>0.137848</td>\n",
              "      <td>0.137132</td>\n",
              "      <td>0.137786</td>\n",
              "      <td>0.148162</td>\n",
              "      <td>0.144360</td>\n",
              "      <td>0.140212</td>\n",
              "      <td>0.139569</td>\n",
              "      <td>0.137746</td>\n",
              "      <td>0.139078</td>\n",
              "      <td>0.146346</td>\n",
              "      <td>0.138870</td>\n",
              "      <td>0.134916</td>\n",
              "      <td>0.147783</td>\n",
              "      <td>0.138158</td>\n",
              "      <td>0.138010</td>\n",
              "      <td>0.137924</td>\n",
              "      <td>0.137945</td>\n",
              "      <td>0.138067</td>\n",
              "      <td>0.137276</td>\n",
              "      <td>0.137474</td>\n",
              "      <td>0.138648</td>\n",
              "      <td>0.139118</td>\n",
              "      <td>0.137669</td>\n",
              "      <td>0.137727</td>\n",
              "      <td>0.141712</td>\n",
              "      <td>0.137811</td>\n",
              "      <td>0.138825</td>\n",
              "      <td>0.138713</td>\n",
              "      <td>0.137949</td>\n",
              "      <td>0.135816</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138180</td>\n",
              "      <td>0.138211</td>\n",
              "      <td>0.137050</td>\n",
              "      <td>0.139103</td>\n",
              "      <td>0.140882</td>\n",
              "      <td>0.138625</td>\n",
              "      <td>0.138923</td>\n",
              "      <td>0.138504</td>\n",
              "      <td>0.137251</td>\n",
              "      <td>0.137114</td>\n",
              "      <td>0.138708</td>\n",
              "      <td>0.138862</td>\n",
              "      <td>0.137848</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>0.140804</td>\n",
              "      <td>0.140277</td>\n",
              "      <td>0.137831</td>\n",
              "      <td>0.138420</td>\n",
              "      <td>0.137559</td>\n",
              "      <td>0.146108</td>\n",
              "      <td>0.138105</td>\n",
              "      <td>0.137986</td>\n",
              "      <td>0.136776</td>\n",
              "      <td>0.138272</td>\n",
              "      <td>0.137808</td>\n",
              "      <td>0.137968</td>\n",
              "      <td>0.138111</td>\n",
              "      <td>0.137828</td>\n",
              "      <td>0.137993</td>\n",
              "      <td>0.138804</td>\n",
              "      <td>0.138373</td>\n",
              "      <td>0.138459</td>\n",
              "      <td>0.138169</td>\n",
              "      <td>0.137990</td>\n",
              "      <td>0.134041</td>\n",
              "      <td>0.137820</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>0.138286</td>\n",
              "      <td>0.138630</td>\n",
              "      <td>0.136178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9189659052158407108</th>\n",
              "      <td>0.138932</td>\n",
              "      <td>0.138699</td>\n",
              "      <td>0.138117</td>\n",
              "      <td>0.137621</td>\n",
              "      <td>0.138920</td>\n",
              "      <td>0.137766</td>\n",
              "      <td>0.138568</td>\n",
              "      <td>0.138200</td>\n",
              "      <td>0.140572</td>\n",
              "      <td>0.140365</td>\n",
              "      <td>0.138838</td>\n",
              "      <td>0.138162</td>\n",
              "      <td>0.139325</td>\n",
              "      <td>0.213018</td>\n",
              "      <td>0.164275</td>\n",
              "      <td>0.141652</td>\n",
              "      <td>0.139104</td>\n",
              "      <td>0.138069</td>\n",
              "      <td>0.136997</td>\n",
              "      <td>0.142442</td>\n",
              "      <td>0.138298</td>\n",
              "      <td>0.157560</td>\n",
              "      <td>0.140603</td>\n",
              "      <td>0.143308</td>\n",
              "      <td>0.139266</td>\n",
              "      <td>0.141019</td>\n",
              "      <td>0.141666</td>\n",
              "      <td>0.139284</td>\n",
              "      <td>0.145634</td>\n",
              "      <td>0.145712</td>\n",
              "      <td>0.138731</td>\n",
              "      <td>0.139108</td>\n",
              "      <td>0.138941</td>\n",
              "      <td>0.138897</td>\n",
              "      <td>0.138374</td>\n",
              "      <td>0.138844</td>\n",
              "      <td>0.147596</td>\n",
              "      <td>0.138761</td>\n",
              "      <td>0.141678</td>\n",
              "      <td>0.141520</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138005</td>\n",
              "      <td>0.139644</td>\n",
              "      <td>0.139885</td>\n",
              "      <td>0.137190</td>\n",
              "      <td>0.140919</td>\n",
              "      <td>0.139032</td>\n",
              "      <td>0.143909</td>\n",
              "      <td>0.139763</td>\n",
              "      <td>0.147707</td>\n",
              "      <td>0.139447</td>\n",
              "      <td>0.144665</td>\n",
              "      <td>0.138382</td>\n",
              "      <td>0.138796</td>\n",
              "      <td>0.139262</td>\n",
              "      <td>0.141341</td>\n",
              "      <td>0.137985</td>\n",
              "      <td>0.139236</td>\n",
              "      <td>0.138246</td>\n",
              "      <td>0.138058</td>\n",
              "      <td>0.130773</td>\n",
              "      <td>0.137865</td>\n",
              "      <td>0.139564</td>\n",
              "      <td>0.142723</td>\n",
              "      <td>0.138340</td>\n",
              "      <td>0.138232</td>\n",
              "      <td>0.139038</td>\n",
              "      <td>0.138716</td>\n",
              "      <td>0.138014</td>\n",
              "      <td>0.138794</td>\n",
              "      <td>0.137751</td>\n",
              "      <td>0.140725</td>\n",
              "      <td>0.148152</td>\n",
              "      <td>0.137645</td>\n",
              "      <td>0.138165</td>\n",
              "      <td>0.149152</td>\n",
              "      <td>0.138912</td>\n",
              "      <td>0.139595</td>\n",
              "      <td>0.139807</td>\n",
              "      <td>0.140419</td>\n",
              "      <td>0.145698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9176143510534135851</th>\n",
              "      <td>0.143208</td>\n",
              "      <td>0.138673</td>\n",
              "      <td>0.139514</td>\n",
              "      <td>0.139114</td>\n",
              "      <td>0.137664</td>\n",
              "      <td>0.137447</td>\n",
              "      <td>0.139833</td>\n",
              "      <td>0.140564</td>\n",
              "      <td>0.144698</td>\n",
              "      <td>0.144440</td>\n",
              "      <td>0.137037</td>\n",
              "      <td>0.139572</td>\n",
              "      <td>0.139007</td>\n",
              "      <td>0.138290</td>\n",
              "      <td>0.145871</td>\n",
              "      <td>0.140543</td>\n",
              "      <td>0.140147</td>\n",
              "      <td>0.137642</td>\n",
              "      <td>0.142022</td>\n",
              "      <td>0.163576</td>\n",
              "      <td>0.139253</td>\n",
              "      <td>0.160965</td>\n",
              "      <td>0.153690</td>\n",
              "      <td>0.138399</td>\n",
              "      <td>0.139201</td>\n",
              "      <td>0.140534</td>\n",
              "      <td>0.140724</td>\n",
              "      <td>0.138407</td>\n",
              "      <td>0.135384</td>\n",
              "      <td>0.140066</td>\n",
              "      <td>0.138851</td>\n",
              "      <td>0.138763</td>\n",
              "      <td>0.138403</td>\n",
              "      <td>0.138128</td>\n",
              "      <td>0.150533</td>\n",
              "      <td>0.138263</td>\n",
              "      <td>0.141087</td>\n",
              "      <td>0.138972</td>\n",
              "      <td>0.137039</td>\n",
              "      <td>0.142258</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138115</td>\n",
              "      <td>0.139960</td>\n",
              "      <td>0.139978</td>\n",
              "      <td>0.140019</td>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.137447</td>\n",
              "      <td>0.136664</td>\n",
              "      <td>0.139216</td>\n",
              "      <td>0.145822</td>\n",
              "      <td>0.140441</td>\n",
              "      <td>0.137722</td>\n",
              "      <td>0.139495</td>\n",
              "      <td>0.139414</td>\n",
              "      <td>0.138127</td>\n",
              "      <td>0.144116</td>\n",
              "      <td>0.140592</td>\n",
              "      <td>0.139934</td>\n",
              "      <td>0.139089</td>\n",
              "      <td>0.139481</td>\n",
              "      <td>0.136901</td>\n",
              "      <td>0.137552</td>\n",
              "      <td>0.137265</td>\n",
              "      <td>0.143057</td>\n",
              "      <td>0.138473</td>\n",
              "      <td>0.138530</td>\n",
              "      <td>0.138036</td>\n",
              "      <td>0.138650</td>\n",
              "      <td>0.138920</td>\n",
              "      <td>0.137099</td>\n",
              "      <td>0.138868</td>\n",
              "      <td>0.138367</td>\n",
              "      <td>0.146220</td>\n",
              "      <td>0.136204</td>\n",
              "      <td>0.138087</td>\n",
              "      <td>0.137317</td>\n",
              "      <td>0.137917</td>\n",
              "      <td>0.138546</td>\n",
              "      <td>0.142601</td>\n",
              "      <td>0.141431</td>\n",
              "      <td>0.142154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9172673334835262304</th>\n",
              "      <td>0.138527</td>\n",
              "      <td>0.138021</td>\n",
              "      <td>0.138274</td>\n",
              "      <td>0.137827</td>\n",
              "      <td>0.137997</td>\n",
              "      <td>0.138037</td>\n",
              "      <td>0.138104</td>\n",
              "      <td>0.138259</td>\n",
              "      <td>0.137633</td>\n",
              "      <td>0.138397</td>\n",
              "      <td>0.138124</td>\n",
              "      <td>0.137687</td>\n",
              "      <td>0.137719</td>\n",
              "      <td>0.147690</td>\n",
              "      <td>0.142882</td>\n",
              "      <td>0.139122</td>\n",
              "      <td>0.138471</td>\n",
              "      <td>0.137915</td>\n",
              "      <td>0.138650</td>\n",
              "      <td>0.143494</td>\n",
              "      <td>0.138325</td>\n",
              "      <td>0.138763</td>\n",
              "      <td>0.139561</td>\n",
              "      <td>0.138153</td>\n",
              "      <td>0.138052</td>\n",
              "      <td>0.137808</td>\n",
              "      <td>0.138060</td>\n",
              "      <td>0.138083</td>\n",
              "      <td>0.138665</td>\n",
              "      <td>0.138258</td>\n",
              "      <td>0.138266</td>\n",
              "      <td>0.137641</td>\n",
              "      <td>0.137953</td>\n",
              "      <td>0.137883</td>\n",
              "      <td>0.139041</td>\n",
              "      <td>0.137951</td>\n",
              "      <td>0.138003</td>\n",
              "      <td>0.138507</td>\n",
              "      <td>0.137875</td>\n",
              "      <td>0.137137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138013</td>\n",
              "      <td>0.137970</td>\n",
              "      <td>0.137831</td>\n",
              "      <td>0.138373</td>\n",
              "      <td>0.139015</td>\n",
              "      <td>0.137767</td>\n",
              "      <td>0.139002</td>\n",
              "      <td>0.138571</td>\n",
              "      <td>0.137622</td>\n",
              "      <td>0.137229</td>\n",
              "      <td>0.138657</td>\n",
              "      <td>0.138131</td>\n",
              "      <td>0.138006</td>\n",
              "      <td>0.137721</td>\n",
              "      <td>0.138751</td>\n",
              "      <td>0.138310</td>\n",
              "      <td>0.138028</td>\n",
              "      <td>0.138110</td>\n",
              "      <td>0.138025</td>\n",
              "      <td>0.135660</td>\n",
              "      <td>0.137991</td>\n",
              "      <td>0.138163</td>\n",
              "      <td>0.137772</td>\n",
              "      <td>0.138156</td>\n",
              "      <td>0.137801</td>\n",
              "      <td>0.138019</td>\n",
              "      <td>0.138045</td>\n",
              "      <td>0.137532</td>\n",
              "      <td>0.137743</td>\n",
              "      <td>0.137996</td>\n",
              "      <td>0.138588</td>\n",
              "      <td>0.140146</td>\n",
              "      <td>0.138013</td>\n",
              "      <td>0.137839</td>\n",
              "      <td>0.137033</td>\n",
              "      <td>0.137969</td>\n",
              "      <td>0.138337</td>\n",
              "      <td>0.138361</td>\n",
              "      <td>0.138813</td>\n",
              "      <td>0.137538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9171475473795142532</th>\n",
              "      <td>0.140720</td>\n",
              "      <td>0.137865</td>\n",
              "      <td>0.138061</td>\n",
              "      <td>0.137633</td>\n",
              "      <td>0.138231</td>\n",
              "      <td>0.138089</td>\n",
              "      <td>0.139009</td>\n",
              "      <td>0.137552</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.140581</td>\n",
              "      <td>0.137960</td>\n",
              "      <td>0.137638</td>\n",
              "      <td>0.138558</td>\n",
              "      <td>0.141247</td>\n",
              "      <td>0.133906</td>\n",
              "      <td>0.138897</td>\n",
              "      <td>0.138973</td>\n",
              "      <td>0.137978</td>\n",
              "      <td>0.139747</td>\n",
              "      <td>0.146615</td>\n",
              "      <td>0.137988</td>\n",
              "      <td>0.138377</td>\n",
              "      <td>0.137588</td>\n",
              "      <td>0.139037</td>\n",
              "      <td>0.138106</td>\n",
              "      <td>0.138201</td>\n",
              "      <td>0.138601</td>\n",
              "      <td>0.138206</td>\n",
              "      <td>0.138902</td>\n",
              "      <td>0.137628</td>\n",
              "      <td>0.138988</td>\n",
              "      <td>0.137200</td>\n",
              "      <td>0.137896</td>\n",
              "      <td>0.137950</td>\n",
              "      <td>0.141161</td>\n",
              "      <td>0.138193</td>\n",
              "      <td>0.138098</td>\n",
              "      <td>0.139383</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>0.136194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138044</td>\n",
              "      <td>0.138177</td>\n",
              "      <td>0.137945</td>\n",
              "      <td>0.138293</td>\n",
              "      <td>0.142048</td>\n",
              "      <td>0.138000</td>\n",
              "      <td>0.138775</td>\n",
              "      <td>0.137968</td>\n",
              "      <td>0.138319</td>\n",
              "      <td>0.138089</td>\n",
              "      <td>0.138580</td>\n",
              "      <td>0.139681</td>\n",
              "      <td>0.138415</td>\n",
              "      <td>0.137954</td>\n",
              "      <td>0.139855</td>\n",
              "      <td>0.139614</td>\n",
              "      <td>0.137906</td>\n",
              "      <td>0.138358</td>\n",
              "      <td>0.137997</td>\n",
              "      <td>0.135661</td>\n",
              "      <td>0.138221</td>\n",
              "      <td>0.138732</td>\n",
              "      <td>0.137743</td>\n",
              "      <td>0.138101</td>\n",
              "      <td>0.138034</td>\n",
              "      <td>0.137962</td>\n",
              "      <td>0.138095</td>\n",
              "      <td>0.138483</td>\n",
              "      <td>0.137764</td>\n",
              "      <td>0.138149</td>\n",
              "      <td>0.139046</td>\n",
              "      <td>0.139895</td>\n",
              "      <td>0.138000</td>\n",
              "      <td>0.137958</td>\n",
              "      <td>0.136061</td>\n",
              "      <td>0.138183</td>\n",
              "      <td>0.138817</td>\n",
              "      <td>0.138060</td>\n",
              "      <td>0.139205</td>\n",
              "      <td>0.137198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9166778629773133902</th>\n",
              "      <td>0.138989</td>\n",
              "      <td>0.137725</td>\n",
              "      <td>0.136520</td>\n",
              "      <td>0.137723</td>\n",
              "      <td>0.138559</td>\n",
              "      <td>0.137951</td>\n",
              "      <td>0.138189</td>\n",
              "      <td>0.138496</td>\n",
              "      <td>0.139470</td>\n",
              "      <td>0.137546</td>\n",
              "      <td>0.138630</td>\n",
              "      <td>0.137676</td>\n",
              "      <td>0.138066</td>\n",
              "      <td>0.158558</td>\n",
              "      <td>0.153516</td>\n",
              "      <td>0.139702</td>\n",
              "      <td>0.137782</td>\n",
              "      <td>0.138073</td>\n",
              "      <td>0.136269</td>\n",
              "      <td>0.138271</td>\n",
              "      <td>0.136644</td>\n",
              "      <td>0.142122</td>\n",
              "      <td>0.140998</td>\n",
              "      <td>0.140776</td>\n",
              "      <td>0.138403</td>\n",
              "      <td>0.137915</td>\n",
              "      <td>0.138410</td>\n",
              "      <td>0.138160</td>\n",
              "      <td>0.141377</td>\n",
              "      <td>0.140371</td>\n",
              "      <td>0.138412</td>\n",
              "      <td>0.136175</td>\n",
              "      <td>0.138426</td>\n",
              "      <td>0.137240</td>\n",
              "      <td>0.137603</td>\n",
              "      <td>0.138815</td>\n",
              "      <td>0.140432</td>\n",
              "      <td>0.136503</td>\n",
              "      <td>0.138786</td>\n",
              "      <td>0.138652</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138021</td>\n",
              "      <td>0.138441</td>\n",
              "      <td>0.139079</td>\n",
              "      <td>0.137444</td>\n",
              "      <td>0.138811</td>\n",
              "      <td>0.138559</td>\n",
              "      <td>0.140123</td>\n",
              "      <td>0.137958</td>\n",
              "      <td>0.140152</td>\n",
              "      <td>0.138944</td>\n",
              "      <td>0.141430</td>\n",
              "      <td>0.137672</td>\n",
              "      <td>0.138352</td>\n",
              "      <td>0.138905</td>\n",
              "      <td>0.135974</td>\n",
              "      <td>0.136886</td>\n",
              "      <td>0.138352</td>\n",
              "      <td>0.137775</td>\n",
              "      <td>0.137755</td>\n",
              "      <td>0.130601</td>\n",
              "      <td>0.138090</td>\n",
              "      <td>0.138606</td>\n",
              "      <td>0.138019</td>\n",
              "      <td>0.137581</td>\n",
              "      <td>0.137746</td>\n",
              "      <td>0.137918</td>\n",
              "      <td>0.138104</td>\n",
              "      <td>0.137426</td>\n",
              "      <td>0.137415</td>\n",
              "      <td>0.137869</td>\n",
              "      <td>0.138233</td>\n",
              "      <td>0.144002</td>\n",
              "      <td>0.138050</td>\n",
              "      <td>0.137533</td>\n",
              "      <td>0.139036</td>\n",
              "      <td>0.138399</td>\n",
              "      <td>0.138330</td>\n",
              "      <td>0.137148</td>\n",
              "      <td>0.138027</td>\n",
              "      <td>0.140283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã 1140 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      -9223121837663643404  ...   9210530975708218054\n",
              "contentId                                   ...                      \n",
              "-9222795471790223670              0.139129  ...              0.136246\n",
              "-9216926795620865886              0.138044  ...              0.138323\n",
              "-9194572880052200111              0.135998  ...              0.153114\n",
              "-9192549002213406534              0.141924  ...              0.148793\n",
              "-9190737901804729417              0.140209  ...              0.136178\n",
              "-9189659052158407108              0.138932  ...              0.145698\n",
              "-9176143510534135851              0.143208  ...              0.142154\n",
              "-9172673334835262304              0.138527  ...              0.137538\n",
              "-9171475473795142532              0.140720  ...              0.137198\n",
              "-9166778629773133902              0.138989  ...              0.140283\n",
              "\n",
              "[10 rows x 1140 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLkFXPcPoB8O",
        "outputId": "f0b7b86e-854b-4dda-89f4-3729405a42a2"
      },
      "source": [
        "len(cf_preds_df.columns)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz-l0JBFoE-_"
      },
      "source": [
        "class CFRecommender:\r\n",
        "    \r\n",
        "    MODEL_NAME = 'Collaborative Filtering'\r\n",
        "    \r\n",
        "    def __init__(self, cf_predictions_df, items_df=None):\r\n",
        "        self.cf_predictions_df = cf_predictions_df\r\n",
        "        self.items_df = items_df\r\n",
        "        \r\n",
        "    def get_model_name(self):\r\n",
        "        return self.MODEL_NAME\r\n",
        "        \r\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\r\n",
        "        # Get and sort the user's predictions\r\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\r\n",
        "                                    .reset_index().rename(columns={user_id: 'recStrength'})\r\n",
        "\r\n",
        "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\r\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['contentId'].isin(items_to_ignore)] \\\r\n",
        "                               .sort_values('recStrength', ascending = False) \\\r\n",
        "                               .head(topn)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            if self.items_df is None:\r\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\r\n",
        "\r\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \r\n",
        "                                                          left_on = 'contentId', \r\n",
        "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\r\n",
        "\r\n",
        "\r\n",
        "        return recommendations_df\r\n",
        "    \r\n",
        "cf_recommender_model = CFRecommender(cf_preds_df, articles_df)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFlzugSwoH0i"
      },
      "source": [
        "Evaluating the Collaborative Filtering model (SVD matrix factorization), we observe that we got Recall@5 (33%) and Recall@10 (46%) values, much higher than Popularity model and Content-Based model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "Z1TOghFJoIWL",
        "outputId": "57b688fd-6b41-4cdf-ca3c-4985e53d3896"
      },
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\r\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\r\n",
        "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\r\n",
        "cf_detailed_results_df.head(10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Collaborative Filtering (SVD Matrix Factorization) model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Collaborative Filtering', 'recall@5': 0.33392994119151115, 'recall@10': 0.46803886474047557}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>_person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>21</td>\n",
              "      <td>46</td>\n",
              "      <td>192</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0.239583</td>\n",
              "      <td>3609194402293569455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>30</td>\n",
              "      <td>56</td>\n",
              "      <td>134</td>\n",
              "      <td>0.223881</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>-2626634673110551643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "      <td>130</td>\n",
              "      <td>0.123077</td>\n",
              "      <td>0.261538</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>38</td>\n",
              "      <td>51</td>\n",
              "      <td>117</td>\n",
              "      <td>0.324786</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>-1443636648652872475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>39</td>\n",
              "      <td>48</td>\n",
              "      <td>88</td>\n",
              "      <td>0.443182</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>-2979881261169775358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>22</td>\n",
              "      <td>34</td>\n",
              "      <td>80</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>-3596626804281480007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>24</td>\n",
              "      <td>32</td>\n",
              "      <td>73</td>\n",
              "      <td>0.328767</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>1116121227607581999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>69</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>692689608292948411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>20</td>\n",
              "      <td>28</td>\n",
              "      <td>69</td>\n",
              "      <td>0.289855</td>\n",
              "      <td>0.405797</td>\n",
              "      <td>-9016528795238256703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "      <td>68</td>\n",
              "      <td>0.338235</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>3636910968448833585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     hits@5_count  hits@10_count  ...  recall@10           _person_id\n",
              "76             21             46  ...   0.239583  3609194402293569455\n",
              "17             30             56  ...   0.417910 -2626634673110551643\n",
              "16             16             34  ...   0.261538 -1032019229384696495\n",
              "10             38             51  ...   0.435897 -1443636648652872475\n",
              "82             39             48  ...   0.545455 -2979881261169775358\n",
              "161            22             34  ...   0.425000 -3596626804281480007\n",
              "65             24             32  ...   0.438356  1116121227607581999\n",
              "81             16             21  ...   0.304348   692689608292948411\n",
              "106            20             28  ...   0.405797 -9016528795238256703\n",
              "52             23             30  ...   0.441176  3636910968448833585\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35O3ViNv0c5G"
      },
      "source": [
        "#Hybrid Recommender\r\n",
        "\r\n",
        "What if we combine Collaborative Filtering and Content-Based Filtering approaches?\r\n",
        "Would that provide us with more accurate recommendations?\r\n",
        "In fact, hybrid methods have performed better than individual approaches in many studies and have being extensively used by researchers and practioners.\r\n",
        "Let's build a simple hybridization method, as an ensemble that takes the weighted average of the normalized CF scores with the Content-Based scores, and ranking by resulting score. In this case, as the CF model is much more accurate than the CB model, the weights for the CF and CB models are 100.0 and 1.0, respectivelly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlUk-OPH0xhl"
      },
      "source": [
        "class HybridRecommender:\r\n",
        "    \r\n",
        "    MODEL_NAME = 'Hybrid'\r\n",
        "    \r\n",
        "    def __init__(self, cb_rec_model, cf_rec_model, items_df, cb_ensemble_weight=1.0, cf_ensemble_weight=1.0):\r\n",
        "        self.cb_rec_model = cb_rec_model\r\n",
        "        self.cf_rec_model = cf_rec_model\r\n",
        "        self.cb_ensemble_weight = cb_ensemble_weight\r\n",
        "        self.cf_ensemble_weight = cf_ensemble_weight\r\n",
        "        self.items_df = items_df\r\n",
        "        \r\n",
        "    def get_model_name(self):\r\n",
        "        return self.MODEL_NAME\r\n",
        "        \r\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\r\n",
        "        #Getting the top-1000 Content-based filtering recommendations\r\n",
        "        cb_recs_df = self.cb_rec_model.recommend_items(user_id, items_to_ignore=items_to_ignore, verbose=verbose,\r\n",
        "                                                           topn=1000).rename(columns={'recStrength': 'recStrengthCB'})\r\n",
        "        \r\n",
        "        #Getting the top-1000 Collaborative filtering recommendations\r\n",
        "        cf_recs_df = self.cf_rec_model.recommend_items(user_id, items_to_ignore=items_to_ignore, verbose=verbose, \r\n",
        "                                                           topn=1000).rename(columns={'recStrength': 'recStrengthCF'})\r\n",
        "        \r\n",
        "        #Combining the results by contentId\r\n",
        "        recs_df = cb_recs_df.merge(cf_recs_df,\r\n",
        "                                   how = 'outer', \r\n",
        "                                   left_on = 'contentId', \r\n",
        "                                   right_on = 'contentId').fillna(0.0)\r\n",
        "        \r\n",
        "        #Computing a hybrid recommendation score based on CF and CB scores\r\n",
        "        #recs_df['recStrengthHybrid'] = recs_df['recStrengthCB'] * recs_df['recStrengthCF'] \r\n",
        "        recs_df['recStrengthHybrid'] = (recs_df['recStrengthCB'] * self.cb_ensemble_weight) \\\r\n",
        "                                     + (recs_df['recStrengthCF'] * self.cf_ensemble_weight)\r\n",
        "        \r\n",
        "        #Sorting recommendations by hybrid score\r\n",
        "        recommendations_df = recs_df.sort_values('recStrengthHybrid', ascending=False).head(topn)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            if self.items_df is None:\r\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\r\n",
        "\r\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \r\n",
        "                                                          left_on = 'contentId', \r\n",
        "                                                          right_on = 'contentId')[['recStrengthHybrid', 'contentId', 'title', 'url', 'lang']]\r\n",
        "\r\n",
        "\r\n",
        "        return recommendations_df\r\n",
        "    \r\n",
        "hybrid_recommender_model = HybridRecommender(content_based_recommender_model, cf_recommender_model, articles_df,\r\n",
        "                                             cb_ensemble_weight=1.0, cf_ensemble_weight=100.0)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KzAZjxG03Ix"
      },
      "source": [
        "We have a new champion!\r\n",
        "Our simple hybrid approach surpasses Content-Based filtering with its combination with Collaborative Filtering. Now we have a Recall@5 of 34.2% and Recall@10 of 47.9%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "8urGZjuN03vm",
        "outputId": "5d43ec20-beb5-42ed-d267-267026bcf75b"
      },
      "source": [
        "print('Evaluating Hybrid model...')\r\n",
        "hybrid_global_metrics, hybrid_detailed_results_df = model_evaluator.evaluate_model(hybrid_recommender_model)\r\n",
        "print('\\nGlobal metrics:\\n%s' % hybrid_global_metrics)\r\n",
        "hybrid_detailed_results_df.head(10)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating Hybrid model...\n",
            "1139 users processed\n",
            "\n",
            "Global metrics:\n",
            "{'modelName': 'Hybrid', 'recall@5': 0.34262336998210174, 'recall@10': 0.4796727179749425}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hits@5_count</th>\n",
              "      <th>hits@10_count</th>\n",
              "      <th>interacted_count</th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "      <th>_person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>192</td>\n",
              "      <td>0.114583</td>\n",
              "      <td>0.239583</td>\n",
              "      <td>3609194402293569455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>31</td>\n",
              "      <td>58</td>\n",
              "      <td>134</td>\n",
              "      <td>0.231343</td>\n",
              "      <td>0.432836</td>\n",
              "      <td>-2626634673110551643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>21</td>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>0.161538</td>\n",
              "      <td>0.284615</td>\n",
              "      <td>-1032019229384696495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>40</td>\n",
              "      <td>51</td>\n",
              "      <td>117</td>\n",
              "      <td>0.341880</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>-1443636648652872475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>38</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>0.431818</td>\n",
              "      <td>0.568182</td>\n",
              "      <td>-2979881261169775358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>23</td>\n",
              "      <td>35</td>\n",
              "      <td>80</td>\n",
              "      <td>0.287500</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>-3596626804281480007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>23</td>\n",
              "      <td>32</td>\n",
              "      <td>73</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.438356</td>\n",
              "      <td>1116121227607581999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>69</td>\n",
              "      <td>0.231884</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>692689608292948411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>20</td>\n",
              "      <td>27</td>\n",
              "      <td>69</td>\n",
              "      <td>0.289855</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>-9016528795238256703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>68</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.426471</td>\n",
              "      <td>3636910968448833585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     hits@5_count  hits@10_count  ...  recall@10           _person_id\n",
              "76             22             46  ...   0.239583  3609194402293569455\n",
              "17             31             58  ...   0.432836 -2626634673110551643\n",
              "16             21             37  ...   0.284615 -1032019229384696495\n",
              "10             40             51  ...   0.435897 -1443636648652872475\n",
              "82             38             50  ...   0.568182 -2979881261169775358\n",
              "161            23             35  ...   0.437500 -3596626804281480007\n",
              "65             23             32  ...   0.438356  1116121227607581999\n",
              "81             16             21  ...   0.304348   692689608292948411\n",
              "106            20             27  ...   0.391304 -9016528795238256703\n",
              "52             22             29  ...   0.426471  3636910968448833585\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y5gPc0V08pk"
      },
      "source": [
        "#Comparing the methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "8Y3SwMtF09zP",
        "outputId": "6dab22f5-2b77-4faf-943d-6fcc17d1fb45"
      },
      "source": [
        "global_metrics_df = pd.DataFrame([cb_global_metrics, pop_global_metrics, cf_global_metrics, hybrid_global_metrics]) \\\r\n",
        "                        .set_index('modelName')\r\n",
        "global_metrics_df"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recall@5</th>\n",
              "      <th>recall@10</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modelName</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Content-Based</th>\n",
              "      <td>0.162874</td>\n",
              "      <td>0.261442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Popularity</th>\n",
              "      <td>0.241882</td>\n",
              "      <td>0.372539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Collaborative Filtering</th>\n",
              "      <td>0.333930</td>\n",
              "      <td>0.468039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hybrid</th>\n",
              "      <td>0.342623</td>\n",
              "      <td>0.479673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         recall@5  recall@10\n",
              "modelName                                   \n",
              "Content-Based            0.162874   0.261442\n",
              "Popularity               0.241882   0.372539\n",
              "Collaborative Filtering  0.333930   0.468039\n",
              "Hybrid                   0.342623   0.479673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "yEwQnD4Z1G6R",
        "outputId": "f4772167-a634-4857-e89c-bea77d4efce7"
      },
      "source": [
        "%matplotlib inline\r\n",
        "ax = global_metrics_df.transpose().plot(kind='bar', figsize=(15,8))\r\n",
        "for p in ax.patches:\r\n",
        "    ax.annotate(\"%.3f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Ela4BQ1JlH"
      },
      "source": [
        "#Testing\r\n",
        "Let's test the best model (Hybrid) for my user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIhvc7cw1LCg"
      },
      "source": [
        "def inspect_interactions(person_id, test_set=True):\r\n",
        "    if test_set:\r\n",
        "        interactions_df = interactions_test_indexed_df\r\n",
        "    else:\r\n",
        "        interactions_df = interactions_train_indexed_df\r\n",
        "    return interactions_df.loc[person_id].merge(articles_df, how = 'left', \r\n",
        "                                                      left_on = 'contentId', \r\n",
        "                                                      right_on = 'contentId') \\\r\n",
        "                          .sort_values('eventStrength', ascending = False)[['eventStrength', \r\n",
        "                                                                          'contentId',\r\n",
        "                                                                          'title', 'url', 'lang']]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ-srNC11PHu"
      },
      "source": [
        "Here we see some articles I interacted in Deskdrop from train set. It can be easily observed that among my main interests are machine learning, deep learning, artificial intelligence, and google cloud platform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "9FIG0P1i1PkE",
        "outputId": "ffdff839-7793-48fa-9764-4873f3789eda"
      },
      "source": [
        "inspect_interactions(-1479311724257856983, test_set=False).head(20)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eventStrength</th>\n",
              "      <th>contentId</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>4.285402</td>\n",
              "      <td>7342707578347442862</td>\n",
              "      <td>At eBay, Machine Learning is Driving Innovativ...</td>\n",
              "      <td>https://www.ebayinc.com/stories/news/at-ebay-m...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.129283</td>\n",
              "      <td>621816023396605502</td>\n",
              "      <td>AI Is Here to Help You Write Emails People Wil...</td>\n",
              "      <td>http://www.wired.com/2016/08/boomerang-using-a...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.044394</td>\n",
              "      <td>-4460374799273064357</td>\n",
              "      <td>Deep Learning for Chatbots, Part 1 - Introduction</td>\n",
              "      <td>http://www.wildml.com/2016/04/deep-learning-fo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>3.954196</td>\n",
              "      <td>-7959318068735027467</td>\n",
              "      <td>Auto-scaling scikit-learn with Spark</td>\n",
              "      <td>https://databricks.com/blog/2016/02/08/auto-sc...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.906891</td>\n",
              "      <td>2589533162305407436</td>\n",
              "      <td>6 reasons why I like KeystoneML</td>\n",
              "      <td>http://radar.oreilly.com/2015/07/6-reasons-why...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.700440</td>\n",
              "      <td>5258604889412591249</td>\n",
              "      <td>Machine Learning Is No Longer Just for Experts</td>\n",
              "      <td>https://hbr.org/2016/10/machine-learning-is-no...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.700440</td>\n",
              "      <td>-398780385766545248</td>\n",
              "      <td>10 Stats About Artificial Intelligence That Wi...</td>\n",
              "      <td>http://www.fool.com/investing/2016/06/19/10-st...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>3.643856</td>\n",
              "      <td>-6467708104873171151</td>\n",
              "      <td>5 reasons your employees aren't sharing their ...</td>\n",
              "      <td>http://justcuriousblog.com/2016/04/5-reasons-y...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3.523562</td>\n",
              "      <td>-4944551138301474550</td>\n",
              "      <td>Algorithms and architecture for job recommenda...</td>\n",
              "      <td>https://www.oreilly.com/ideas/algorithms-and-a...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3.459432</td>\n",
              "      <td>-8377626164558006982</td>\n",
              "      <td>Bad Writing Is Destroying Your Company's Produ...</td>\n",
              "      <td>https://hbr.org/2016/09/bad-writing-is-destroy...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>3.459432</td>\n",
              "      <td>444378495316508239</td>\n",
              "      <td>How to choose algorithms for Microsoft Azure M...</td>\n",
              "      <td>https://azure.microsoft.com/en-us/documentatio...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.321928</td>\n",
              "      <td>2468005329717107277</td>\n",
              "      <td>How Netflix does A/B Testing - uxdesign.cc - U...</td>\n",
              "      <td>https://uxdesign.cc/how-netflix-does-a-b-testi...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>3.321928</td>\n",
              "      <td>-8085935119790093311</td>\n",
              "      <td>Graph Capabilities with the Elastic Stack</td>\n",
              "      <td>https://www.elastic.co/webinars/sneak-peek-of-...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>-1429167743746492970</td>\n",
              "      <td>Building with Watson Technical Web Series</td>\n",
              "      <td>https://www-304.ibm.com/partnerworld/wps/servl...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>6340108943344143104</td>\n",
              "      <td>Text summarization with TensorFlow</td>\n",
              "      <td>https://research.googleblog.com/2016/08/text-s...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>1525777409079968377</td>\n",
              "      <td>Probabilistic Programming</td>\n",
              "      <td>http://probabilistic-programming.org/wiki/Home</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3.169925</td>\n",
              "      <td>-5756697018315640725</td>\n",
              "      <td>Being A Developer After 40 - Free Code Camp</td>\n",
              "      <td>https://medium.freecodecamp.com/being-a-develo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>3.087463</td>\n",
              "      <td>2623290164732957912</td>\n",
              "      <td>Creative Applications of Deep Learning with Te...</td>\n",
              "      <td>https://www.kadenze.com/courses/creative-appli...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>279771472506428952</td>\n",
              "      <td>5 Unique Features Of Google Compute Engine Tha...</td>\n",
              "      <td>http://www.forbes.com/sites/janakirammsv/2016/...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>2.906891</td>\n",
              "      <td>-3920124114454832425</td>\n",
              "      <td>Worldwide Ops in Minutes with DataStax &amp; Cloud</td>\n",
              "      <td>http://www.datastax.com/2016/01/datastax-enter...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     eventStrength  ...  lang\n",
              "115       4.285402  ...    en\n",
              "38        4.129283  ...    en\n",
              "8         4.044394  ...    en\n",
              "116       3.954196  ...    en\n",
              "10        3.906891  ...    en\n",
              "28        3.700440  ...    en\n",
              "6         3.700440  ...    en\n",
              "113       3.643856  ...    en\n",
              "42        3.523562  ...    en\n",
              "43        3.459432  ...    en\n",
              "41        3.459432  ...    en\n",
              "3         3.321928  ...    en\n",
              "101       3.321928  ...    en\n",
              "107       3.169925  ...    pt\n",
              "16        3.169925  ...    en\n",
              "49        3.169925  ...    en\n",
              "44        3.169925  ...    en\n",
              "97        3.087463  ...    en\n",
              "32        3.000000  ...    en\n",
              "78        2.906891  ...    en\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfOefrBD1fjT"
      },
      "source": [
        "The recommendations really matches my interests, as I would read all of them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "1ooQRvEw1gKx",
        "outputId": "d8a36214-77f7-4b13-f673-a2eb83c8f8e2"
      },
      "source": [
        "hybrid_recommender_model.recommend_items(-1479311724257856983, topn=20, verbose=True)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recStrengthHybrid</th>\n",
              "      <th>contentId</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25.436876</td>\n",
              "      <td>3269302169678465882</td>\n",
              "      <td>The barbell effect of machine learning.</td>\n",
              "      <td>http://techcrunch.com/2016/06/02/the-barbell-e...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.369932</td>\n",
              "      <td>-8085935119790093311</td>\n",
              "      <td>Graph Capabilities with the Elastic Stack</td>\n",
              "      <td>https://www.elastic.co/webinars/sneak-peek-of-...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.493428</td>\n",
              "      <td>1005751836898964351</td>\n",
              "      <td>Seria Stranger Things uma obra de arte do algo...</td>\n",
              "      <td>https://www.linkedin.com/pulse/seria-stranger-...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24.382997</td>\n",
              "      <td>-8377626164558006982</td>\n",
              "      <td>Bad Writing Is Destroying Your Company's Produ...</td>\n",
              "      <td>https://hbr.org/2016/09/bad-writing-is-destroy...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.362064</td>\n",
              "      <td>-6727357771678896471</td>\n",
              "      <td>This Super Accurate Portrait Selection Tech Us...</td>\n",
              "      <td>http://petapixel.com/2016/06/29/super-accurate...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>24.190327</td>\n",
              "      <td>-8190931845319543363</td>\n",
              "      <td>Machine Learning Is At The Very Peak Of Its Hy...</td>\n",
              "      <td>https://arc.applause.com/2016/08/17/gartner-hy...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>24.172285</td>\n",
              "      <td>7395435905985567130</td>\n",
              "      <td>The AI business landscape</td>\n",
              "      <td>https://www.oreilly.com/ideas/the-ai-business-...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>23.932289</td>\n",
              "      <td>5092635400707338872</td>\n",
              "      <td>Power to the People: How One Unknown Group of ...</td>\n",
              "      <td>https://medium.com/@atduskgreg/power-to-the-pe...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>23.865716</td>\n",
              "      <td>-5253644367331262405</td>\n",
              "      <td>Hello, TensorFlow!</td>\n",
              "      <td>https://www.oreilly.com/learning/hello-tensorflow</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>23.811519</td>\n",
              "      <td>1549650080907932816</td>\n",
              "      <td>Spark comparison: AWS vs. GCP</td>\n",
              "      <td>https://www.oreilly.com/ideas/spark-comparison...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>23.537832</td>\n",
              "      <td>621816023396605502</td>\n",
              "      <td>AI Is Here to Help You Write Emails People Wil...</td>\n",
              "      <td>http://www.wired.com/2016/08/boomerang-using-a...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>23.195716</td>\n",
              "      <td>-1901742495252324928</td>\n",
              "      <td>Designing smart notifications</td>\n",
              "      <td>https://medium.com/@intercom/designing-smart-n...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23.101347</td>\n",
              "      <td>882422233694040097</td>\n",
              "      <td>InfogrÃ¡fico: Algoritmos para Aprendizado de MÃ¡...</td>\n",
              "      <td>https://www.infoq.com/br/news/2016/07/infograf...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>22.725769</td>\n",
              "      <td>2468005329717107277</td>\n",
              "      <td>How Netflix does A/B Testing - uxdesign.cc - U...</td>\n",
              "      <td>https://uxdesign.cc/how-netflix-does-a-b-testi...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>22.561032</td>\n",
              "      <td>-5756697018315640725</td>\n",
              "      <td>Being A Developer After 40 - Free Code Camp</td>\n",
              "      <td>https://medium.freecodecamp.com/being-a-develo...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>22.448418</td>\n",
              "      <td>-4944551138301474550</td>\n",
              "      <td>Algorithms and architecture for job recommenda...</td>\n",
              "      <td>https://www.oreilly.com/ideas/algorithms-and-a...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22.342822</td>\n",
              "      <td>1415230502586719648</td>\n",
              "      <td>Machine Learning Is Redefining The Enterprise ...</td>\n",
              "      <td>http://www.forbes.com/sites/louiscolumbus/2016...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>22.311658</td>\n",
              "      <td>-8771338872124599367</td>\n",
              "      <td>FuncionÃ¡rios do mÃªs no CoolHow: os Slackbots -...</td>\n",
              "      <td>https://medium.com/coolhow-creative-lab/funcio...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>22.278853</td>\n",
              "      <td>5258604889412591249</td>\n",
              "      <td>Machine Learning Is No Longer Just for Experts</td>\n",
              "      <td>https://hbr.org/2016/10/machine-learning-is-no...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>22.239822</td>\n",
              "      <td>-5027816744653977347</td>\n",
              "      <td>Apple acquires Turi, a machine learning company</td>\n",
              "      <td>https://techcrunch.com/2016/08/05/apple-acquir...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    recStrengthHybrid  ...  lang\n",
              "0           25.436876  ...    en\n",
              "1           25.369932  ...    en\n",
              "2           24.493428  ...    pt\n",
              "3           24.382997  ...    en\n",
              "4           24.362064  ...    en\n",
              "5           24.190327  ...    en\n",
              "6           24.172285  ...    en\n",
              "7           23.932289  ...    en\n",
              "8           23.865716  ...    en\n",
              "9           23.811519  ...    en\n",
              "10          23.537832  ...    en\n",
              "11          23.195716  ...    en\n",
              "12          23.101347  ...    pt\n",
              "13          22.725769  ...    en\n",
              "14          22.561032  ...    en\n",
              "15          22.448418  ...    en\n",
              "16          22.342822  ...    en\n",
              "17          22.311658  ...    pt\n",
              "18          22.278853  ...    en\n",
              "19          22.239822  ...    en\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT0Lfzc01lu2"
      },
      "source": [
        "#Conclusion\r\n",
        "\r\n",
        "In this notebook, we've explored and compared the main Recommender Systems techniques on CI&T Deskdrop dataset. It could be observed that for articles recommendation, content-based filtering and a hybrid method performed better than Collaborative Filtering alone.\r\n",
        "\r\n",
        "There is large room for improvements of the results. Here are some tips:\r\n",
        "\r\n",
        "In this example, we've completely ignored the time, considering that all articles were available to be recommended to users at any time. A better approach would be to filter only articles that were available for users at a given time.\r\n",
        "You could leverage the available contextual information to model users preferences across time (period of day, day of week, month), location (country and state/district) and devices (browser, mobile native app).\r\n",
        "This contextual information can be easily incorporated in Learn-to-Rank models (like XGBoost Gradient Boosting Decision Trees with ranking objective), Logistic models (with categorical features One-Hot encoded or Feature Hashed), and Wide & Deep models, which is implemented in TensorFlow. Take a look in the summary my solution shared for Outbrain Click Prediction competition.\r\n",
        "Those basic techniques were used for didactic purposes. There are more advanced techniques in RecSys research community, specially advanced Matrix Factorization and Deep Learning models.\r\n",
        "You can know more about state-of-the-art methods published in Recommender Systems on ACM RecSys conference.\r\n",
        "If you are more like practioner than researcher, you might try some Collaborative Filtering frameworks in this dataset, like surprise, mrec, python-recsys and Spark ALS Matrix Factorization (distributed implementation for large datasets).\r\n",
        "Take a look in this presentation where I describe a production recommender system, focused on Content-Based Filtering and Topic Modeling techniques."
      ]
    }
  ]
}